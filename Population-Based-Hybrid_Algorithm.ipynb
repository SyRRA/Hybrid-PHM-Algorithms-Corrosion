{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"ed37a9ec-a229-4bb5-b705-ffb87cdde510\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id !== undefined) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var element_id = msg.content.text.trim();\n",
       "            Bokeh.index[element_id].model.document.clear();\n",
       "            delete Bokeh.index[element_id];\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"ed37a9ec-a229-4bb5-b705-ffb87cdde510\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"ed37a9ec-a229-4bb5-b705-ffb87cdde510\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid 'ed37a9ec-a229-4bb5-b705-ffb87cdde510' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.16.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.16.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.16.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.16.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.16.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.16.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.16.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.16.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.16.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.16.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"ed37a9ec-a229-4bb5-b705-ffb87cdde510\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"ed37a9ec-a229-4bb5-b705-ffb87cdde510\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"ed37a9ec-a229-4bb5-b705-ffb87cdde510\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid 'ed37a9ec-a229-4bb5-b705-ffb87cdde510' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.16.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.16.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.16.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.16.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.16.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.16.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.16.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.16.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.16.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.16.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"ed37a9ec-a229-4bb5-b705-ffb87cdde510\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bokeh.plotting import figure, output_notebook, show\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.io import push_notebook\n",
    "from ipywidgets import interact\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "# output to the IPython Notebook\n",
    "output_notebook()\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from scipy.stats import norm\n",
    "import bisect\n",
    "from sklearn.neighbors.kde import KernelDensity\n",
    "from scipy.stats import genextreme as gev\n",
    "import scipy.stats as ss\n",
    "from scipy.stats import gamma\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "# import seaborn\n",
    "import seaborn as sns\n",
    "# settings for seaborn plotting style\n",
    "sns.set(color_codes=True)\n",
    "# settings for seaborn plot sizes\n",
    "sns.set(rc={'figure.figsize':(4.5,3)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- Input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some characteristics for plots\n",
    "plt.rc('legend',**{'fontsize':16})\n",
    "plt.rc('xtick', labelsize=15) \n",
    "plt.rc('ytick', labelsize=15) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ILI_time</th>\n",
       "      <th>Actual_Pit_No</th>\n",
       "      <th>Estimated_Pit_No</th>\n",
       "      <th>KLD</th>\n",
       "      <th>ChiSq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ILI_1</th>\n",
       "      <td>30</td>\n",
       "      <td>2374</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ILI_2</th>\n",
       "      <td>35</td>\n",
       "      <td>414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ILI_3</th>\n",
       "      <td>40</td>\n",
       "      <td>381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediction Time</th>\n",
       "      <td>50</td>\n",
       "      <td>790</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ILI_time  Actual_Pit_No  Estimated_Pit_No  KLD  ChiSq\n",
       "ILI_1                  30           2374               0.0  0.0    0.0\n",
       "ILI_2                  35            414               0.0  0.0    0.0\n",
       "ILI_3                  40            381               0.0  0.0    0.0\n",
       "Prediction Time        50            790               0.0  0.0    0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_number = 22331\n",
    "np.random.seed(seed_number)\n",
    "Pit_generation_rate = 80 # assumption\n",
    "ScalePar = 3.5    # Assumed scale parameter of the gamma process\n",
    "k  = 0.12 # Ossai 2016 paper\n",
    "nu = 0.771  # Ossai 2016 paper\n",
    "ILI_no = 3+1   # I aasumed there are 3 ILI datasets, plus the prediction time\n",
    "ILI_info = pd.DataFrame(0, index = range(1, ILI_no + 1), columns = range(5)).astype(float)\n",
    "ILI_info.columns = ['ILI_time', 'Actual_Pit_No', 'Estimated_Pit_No', 'KLD', 'ChiSq']\n",
    "ILI_info.index = ['ILI_1', 'ILI_2', 'ILI_3', 'Prediction Time']\n",
    "ILI_info.ILI_time = [30, 35, 40, 50] # I assumed that the first ILI happened 30 years after starting operation and so on\n",
    "ILI_info.Actual_Pit_No = [np.random.poisson(Pit_generation_rate*ILI_info.ILI_time[0]),\\\n",
    "                       np.random.poisson(Pit_generation_rate*(ILI_info.ILI_time[1]-ILI_info.ILI_time[0])),\\\n",
    "                       np.random.poisson(Pit_generation_rate*(ILI_info.ILI_time[2]-ILI_info.ILI_time[1])),\\\n",
    "                       np.random.poisson(Pit_generation_rate*(ILI_info.ILI_time[3]-ILI_info.ILI_time[2]))]\n",
    "ILI_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PWT = 8.41 # mm, pipe wall thickness\n",
    "# Detection tool's specifications  \n",
    "detection_threshold = 0.1 * PWT # from Dann and Maes 2018\n",
    "credible_pit_depth_threshold  = 0.2 * PWT # from Dann and Maes 2018\n",
    "a_ILI = 2.04/100*PWT  # from Zhang and Zhou 2013\n",
    "b_ILI = 0.97  # from Zhang and Zhou 2013\n",
    "ILI_percent_error = 5.97/100   # from Zhang and Zhou 2013\n",
    "ILI_error_STD = (ILI_percent_error * PWT) # from Zhang and Zhou 2013"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Generating synthetic actual and measured depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the time steps given start and end point of each gamma process\n",
    "t0 = 0;\n",
    "h = 1 # time step\n",
    "def time_info (start, end):\n",
    "    T = end - start\n",
    "    N = np.int(T / h) + 1; # No. of time steps\n",
    "    t = np.linspace(t0, T, N)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure specifications for Bokeh plots\n",
    "p = figure(x_axis_label='t (year)',\\\n",
    "           y_axis_label='depth (mm)', plot_height = 700, plot_width = 700)      \n",
    "p.xaxis.axis_line_width = 3\n",
    "p.xaxis.major_label_text_font_size = \"15pt\"\n",
    "p.yaxis.axis_line_width = 3 \n",
    "p.yaxis.major_label_text_font_size = \"15pt\"\n",
    "p.xaxis.axis_label_text_font_size  = \"20pt\"\n",
    "p.yaxis.axis_label_text_font_size  = \"20pt\"\n",
    "p.axis.minor_tick_in  = 2\n",
    "p.axis.minor_tick_out = 5\n",
    "p.axis.axis_label_text_alpha=0.9\n",
    "p.legend.label_text_font_size = \"20pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2a2b7654def48d9b087b633b243534d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2374), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-ef39a4fc580e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mMeasured_Depth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma_ILI\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb_ILI\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mInitiation_1_Actual_Depth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m             \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mILI_error_STD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m             \u001b[0mMeasured_Depth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'NaN'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mt0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mnu\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mScalePar\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mline_width\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlegend\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m'Before ILI 1 : '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mILI_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mActual_Pit_No\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m       \u001b[0mcolor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'yellow'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    187\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[1;34m(self, indexer, value)\u001b[0m\n\u001b[0;32m    613\u001b[0m                 \u001b[1;31m# scalar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 615\u001b[1;33m                     \u001b[0msetter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    616\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36msetter\u001b[1;34m(item, v)\u001b[0m\n\u001b[0;32m    536\u001b[0m                     \u001b[1;31m# set the item, possibly having a dtype change\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m                     \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 538\u001b[1;33m                     \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m                     \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m                     \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_update_cacher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclear\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mcopy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m   5108\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5109\u001b[0m         \"\"\"\n\u001b[1;32m-> 5110\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5111\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mcopy\u001b[1;34m(self, deep, mgr)\u001b[0m\n\u001b[0;32m   3918\u001b[0m             \u001b[0mnew_axes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3919\u001b[0m         return self.apply('copy', axes=new_axes, deep=deep,\n\u001b[1;32m-> 3920\u001b[1;33m                           do_integrity_check=False)\n\u001b[0m\u001b[0;32m   3921\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3922\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mas_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[0;32m   3579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3580\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mgr'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3581\u001b[1;33m             \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3582\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mcopy\u001b[1;34m(self, deep, mgr)\u001b[0m\n\u001b[0;32m    776\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 778\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    779\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_block_same_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Generating synthetic actual and measured depth for those pits that are initiated before ILI 1 at time zero\n",
    "np.random.seed(seed_number)\n",
    "t1 = time_info (0, ILI_info.ILI_time[3])\n",
    "# The actual depth for those pits that are initiated before ILI_1\n",
    "Initiation_1_Actual_Depth = pd.DataFrame(0, index = range(1, ILI_info.Actual_Pit_No[0]+1), columns = range(ILI_no))\n",
    "# POD_1 is probability of detection based on the actual depth\n",
    "POD_1 = pd.DataFrame(0, index = range(1, ILI_info.Actual_Pit_No[0]+1), columns = range(ILI_no))\n",
    "Measured_Depth = pd.DataFrame(0, index = range(1, 2), columns = range(10)) # 10 = 4 (no of measurement for the first set)\\\n",
    " # + 3 (no of measurements for the second set) + 2 (..third.) + 1 (..forth.)\n",
    "ILI_Index = 1\n",
    "for i in tqdm(range(1, ILI_info.Actual_Pit_No[ILI_Index-1]+1)):\n",
    "    for j in range(0, ILI_no):\n",
    "        g = np.random.gamma( k*(ILI_info.ILI_time[j]-np.random.uniform(0, ILI_info.ILI_time[0]))**nu, scale = ScalePar) ; # degradation increment\n",
    "        Initiation_1_Actual_Depth.loc[i, j] = g # storing the actual depth at ILI time and prediction time\n",
    "        POD_1.loc[i, j] = 1 - np.exp(- Initiation_1_Actual_Depth.loc[i, j] / detection_threshold) \n",
    "        if POD_1.loc[i, j] > np.random.uniform(): #  if a pit will be detected or not\n",
    "            Measured_Depth.loc[i, j] = a_ILI + b_ILI * Initiation_1_Actual_Depth.loc[i, j] \\\n",
    "            + np.random.normal (0, ILI_error_STD)\n",
    "        else:\n",
    "            Measured_Depth.loc[i, j] = 'NaN'\n",
    "        \n",
    "p.line(t1, k*(t1-t0)**nu*ScalePar , line_width = 2, legend ='Before ILI 1 : ' + str (ILI_info.Actual_Pit_No[0]),\\\n",
    "       color = 'yellow')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual comparison of samples data and actual distribution\n",
    "tt = np.linspace(t0, 50, 1000)\n",
    "bins_no = 100\n",
    "plt.figure(figsize=(12, 9))\n",
    "plt.xlabel('Pit Depth (mm)', fontsize = 16)\n",
    "plt.ylabel('PDF', fontsize = 16)\n",
    "plt.plot(tt, gamma.pdf(tt, k*(ILI_info.ILI_time[0]-t0)**nu, scale = ScalePar), c='green', linestyle='--', alpha=0.5,\\\n",
    "         linewidth=3, label='Actual pit depth dist. ILI_1') \n",
    "plt.hist(Initiation_1_Actual_Depth[0], bins_no, color = 'green',  histtype='step', normed=True, linewidth=2,\\\n",
    "          label='Sampled actual depth at ILI_1');\n",
    "pltEndPoint = 14\n",
    "plt.xlim([0, pltEndPoint]);\n",
    "plt.title('' , fontsize = 16)\n",
    "plt.legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating synthetic actual and measured depth for those pits that are initiated between ILI 1 and ILI 2\n",
    "np.random.seed(seed_number)\n",
    "t2 = time_info (ILI_info.ILI_time[0], ILI_info.ILI_time[3])\n",
    "Initiation_2_Actual_Depth = pd.DataFrame(0, index = range(1, ILI_info.Actual_Pit_No[1]+1), columns = range(ILI_no-1))\n",
    "POD_2 = pd.DataFrame(0, index = range(1, ILI_info.Actual_Pit_No[1]+1), columns = range(1, ILI_no-1))\n",
    "ILI_Index = 2\n",
    "for i in range (1, ILI_info.Actual_Pit_No[ILI_Index-1]+1):\n",
    "    for j in range(1, ILI_no):\n",
    "        g = np.random.gamma(k*(ILI_info.ILI_time[j]-np.random.uniform(ILI_info.ILI_time[0], ILI_info.ILI_time[1]))**nu, scale = ScalePar) ;\n",
    "        Initiation_2_Actual_Depth.loc[i, j-1] = g\n",
    "        POD_2.loc[i, j] = 1 - np.exp(- Initiation_2_Actual_Depth.loc[i, j-1] / detection_threshold) \n",
    "        if POD_2.loc[i, j] > np.random.uniform():\n",
    "            Measured_Depth.loc[i, j + 3] = a_ILI + b_ILI * Initiation_2_Actual_Depth.loc[i, j-1] \\\n",
    "            + np.random.normal (0, ILI_error_STD)\n",
    "        else:\n",
    "            Measured_Depth.loc[i, j + 3] = 'NaN'\n",
    "        \n",
    "p.line(ILI_info.ILI_time[0] + t2, k*(t2-t0)**nu*ScalePar , line_width = 2, legend ='Between ILI 1 & 2 : ' \\\n",
    "       + str (ILI_info.Actual_Pit_No[1]), color = 'yellow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual comparison of samples data and actual distribution\n",
    "plt.figure(figsize=(12, 9))\n",
    "plt.xlabel('Pit Depth(mm)', fontsize = 16)\n",
    "plt.ylabel('PDF', fontsize = 16)\n",
    "plt.plot(tt, gamma.pdf(tt, k*(ILI_info.ILI_time[3]-ILI_info.ILI_time[0])**nu, scale = ScalePar), c='green', linestyle='--', alpha=0.5,  linewidth=3,\\\n",
    "         label='Actual pit depth dist. ILI_2_2') \n",
    "plt.hist(Initiation_2_Actual_Depth[2], bins_no, color = 'green',  histtype='step', normed=True, linewidth=2,\\\n",
    "         label='Sampled actual depth at ILI_2_2');\n",
    "\n",
    "plt.xlim([0, 18]);\n",
    "plt.title('' , fontsize = 16)\n",
    "plt.legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating synthetic actual and measured depth for those pits that are initiated between ILI 2 and ILI 3\n",
    "np.random.seed(seed_number)\n",
    "t3 = time_info (ILI_info.ILI_time[1], ILI_info.ILI_time[3])\n",
    "Initiation_3_Actual_Depth = pd.DataFrame(0, index = range(1, ILI_info.Actual_Pit_No[2]+1), columns = range(1, ILI_no-2))\n",
    "POD_3 = pd.DataFrame(0, index = range(1, ILI_info.Actual_Pit_No[2]+1), columns = range(1, ILI_no-2))\n",
    "ILI_Index = 3\n",
    "for i in tqdm(range(1, ILI_info.Actual_Pit_No[ILI_Index-1]+1)):\n",
    "    for j in range (2, ILI_no):\n",
    "        g = np.random.gamma(k*(ILI_info.ILI_time[j]-np.random.uniform(ILI_info.ILI_time[1], ILI_info.ILI_time[2]))**nu, scale = ScalePar) ;\n",
    "        Initiation_3_Actual_Depth.loc[i, j-2] = g\n",
    "        POD_3.loc[i, j] = 1 - np.exp(- Initiation_3_Actual_Depth.loc[i, j-2] / detection_threshold) \n",
    "        if POD_3.loc[i, j] > np.random.uniform():\n",
    "            Measured_Depth.loc[i, j + 5] = a_ILI + b_ILI * Initiation_3_Actual_Depth.loc[i, j-2] \\\n",
    "            + np.random.normal (0, ILI_error_STD)\n",
    "        else:\n",
    "            Measured_Depth.loc[i, j + 5] = 'NaN'                \n",
    "p.line(ILI_info.ILI_time[1] + t3, k*(t3-t0)**nu*ScalePar , line_width = 2, legend ='Between ILI 2 & 3 : ' \\\n",
    "       + str (ILI_info.Actual_Pit_No[2]), color = 'yellow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual comparison of samples data and actual distribution\n",
    "\n",
    "plt.figure(figsize=(12, 9))\n",
    "plt.xlabel('Pit Depth(mm)', fontsize = 16)\n",
    "plt.ylabel('PDF', fontsize = 16)\n",
    "plt.plot(tt, gamma.pdf(tt, k*(ILI_info.ILI_time[3]-ILI_info.ILI_time[1])**nu, scale = ScalePar), c='green', linestyle='--', alpha=0.5,  linewidth=3,\\\n",
    "         label='Actual pit depth dist. ILI_3') \n",
    "plt.hist(Initiation_3_Actual_Depth[1], bins_no, color = 'green',  histtype='step', normed=True, linewidth=2,\\\n",
    "         label='Sampled actual depth at ILI_3');\n",
    "\n",
    "plt.title('' , fontsize = 16)\n",
    "plt.legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating synthetic actual and measured depth for those pits that are initiated between ILI 3 and prediction time\n",
    "np.random.seed(seed_number)\n",
    "t4 = time_info (ILI_info.ILI_time[2], ILI_info.ILI_time[3])\n",
    "Prediction_Actual_Depth = pd.DataFrame(0, index = range(1, ILI_info.Actual_Pit_No[3]+1), columns = range(ILI_no-3))\n",
    "POD_4 = pd.DataFrame(0, index = range(1, ILI_info.Actual_Pit_No[3]+1), columns = range(ILI_no-2))\n",
    "ILI_Index = 4 # This is for prediction and it is not an ILI\n",
    "for i in tqdm(range(1, ILI_info.Actual_Pit_No[ILI_Index-1]+1)):\n",
    "    for j in range (3, ILI_no):\n",
    "        g = np.random.gamma(k*(ILI_info.ILI_time[j]-np.random.uniform(ILI_info.ILI_time[2],ILI_info.ILI_time[3]))**nu, scale = ScalePar) ;           \n",
    "        Prediction_Actual_Depth.loc[i, j-3] = g\n",
    "        POD_4.loc[i, j] = 1 - np.exp(- Prediction_Actual_Depth.loc[i, j-3] / detection_threshold) \n",
    "        if POD_4.loc[i, j] > np.random.uniform():\n",
    "            Measured_Depth.loc[i, j + 6] = a_ILI + b_ILI * Prediction_Actual_Depth.loc[i, j-3] \\\n",
    "                + np.random.normal (0, ILI_error_STD)\n",
    "        else:\n",
    "            Measured_Depth.loc[i, j + 6] = 'NaN'                \n",
    "p.line(ILI_info.ILI_time[2] + t4, k*(t4-t0)**nu*ScalePar , line_width = 2, legend ='After ILI 3 : ' \\\n",
    "       + str (ILI_info.Actual_Pit_No[3]), color = 'yellow')\n",
    "show(p) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual comparison of samples data and actual distribution\n",
    "\n",
    "plt.figure(figsize=(12, 9))\n",
    "plt.xlabel('Pit Depth(mm)', fontsize = 16)\n",
    "plt.ylabel('PDF', fontsize = 16)\n",
    "plt.plot(tt, gamma.pdf(tt, k*(ILI_info.ILI_time[3]-ILI_info.ILI_time[2])**nu, scale = ScalePar), c='green', linestyle='--', alpha=0.5,  linewidth=3,\\\n",
    "         label='Actual pit depth dist. Prediction') \n",
    "plt.hist(Prediction_Actual_Depth[0], bins_no, color = 'green',  histtype='step', normed=True, linewidth=2,\\\n",
    "         label='Sampled actual depth at Prediction');\n",
    "plt.xlim([0, 8]);\n",
    "\n",
    "plt.title('' , fontsize = 16)\n",
    "plt.legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the NaN values from measurements \n",
    "Cleaned_Measured_Depth_Simulated = pd.DataFrame(0, index = range(1, ILI_info.Actual_Pit_No[0]+1), columns = range(10)) \n",
    "No_Detected_Pits = pd.DataFrame(0, index = range(1, 2), columns = range(10))\n",
    "for q in range(0,4):\n",
    "    if q == 0: # Columns 0 to 3 of Measured_Depth are belong to those pits generated before ILI 1\n",
    "        v = 0\n",
    "        u = 4\n",
    "    elif q == 1: # Columns 4 to 6 of Measured_Depth are belong to those pits generated beteween ILI 1 and 2\n",
    "        v = 4\n",
    "        u = 7\n",
    "    elif q == 2: # Columns 7 to 8 of Measured_Depth are belong to those pits generated beteween ILI 2 and 3\n",
    "        v = 7\n",
    "        u = 9\n",
    "    elif q == 3: # Column 9 of Measured_Depth are belong to those pits generated beteween ILI 3 and prediction time\n",
    "        v = 9\n",
    "        u = 10        \n",
    "    for j in range (v, u):\n",
    "        ii = 1\n",
    "        for i in range(1, ILI_info.Actual_Pit_No[q]+1):\n",
    "            if isinstance(Measured_Depth.loc[i,j], str) == False:                \n",
    "                Cleaned_Measured_Depth_Simulated.loc[ii,j] = Measured_Depth.loc[i,j]\n",
    "                No_Detected_Pits.loc[1, j] = No_Detected_Pits.loc[1, j] + 1\n",
    "                ii = ii + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cleaned_Measured_Depth_Simulated.columns = ['Y_1_1', 'Y_2_1', 'Y_3_1', 'Y_4_1', 'Y_2_2', 'Y_3_2', 'Y_4_2',\\\n",
    "                                 'Y_3_3', 'Y_3_4', 'Y_4_4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cleaned_Measured_Depth_Simulated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the generated synthetic data\n",
    "Measured_Depth.to_csv('Measured_Depth.csv')\n",
    "Initiation_1_Actual_Depth.to_csv('Initiation_1_Actual_Depth.csv')\n",
    "Initiation_2_Actual_Depth.to_csv('Initiation_2_Actual_Depth.csv')\n",
    "Initiation_3_Actual_Depth.to_csv('Initiation_3_Actual_Depth.csv')\n",
    "Prediction_Actual_Depth.to_csv('Prediction_Actual_Depth.csv')\n",
    "Cleaned_Measured_Depth_Simulated.to_csv('Cleaned_Measured_Depth_Simulated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_1 = No_Detected_Pits[0] # Number of detected pits at ILI 1\n",
    "m_2 = No_Detected_Pits[1] + No_Detected_Pits[4] # Number of detected pits at ILI 2\n",
    "m_3 = No_Detected_Pits[2] + No_Detected_Pits[5] + No_Detected_Pits[7] # Number of detected pits at ILI 3\n",
    "m_4 = No_Detected_Pits[3] + No_Detected_Pits[6] + No_Detected_Pits[8] + No_Detected_Pits[9] # Number of detected pits at prediction time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-1-Add POFC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section false call error is added to consider POFC in synthetic data generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-1-1 ILI_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of true calls at each ILI\n",
    "No_TrueCalled_Pits = pd.DataFrame(0, index = range(1, 2), columns = range(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing the PMF of the actual depth of existing pits and the PMF of measurements of detected pits at ILI_1\n",
    "frequency_info_1 = pd.DataFrame(0, index = range(1, bins_no+1), columns = range(6)).astype(float)\n",
    "frequency_info_1.columns = ['actual_N','detected_N', 'reported_N', 'estimated_N_WO_POD', 'estimated_N_W_POD',\\\n",
    "                            'rounded_estimated_N_W_POD']\n",
    "bins_start_1 = np.int(np.min(Initiation_1_Actual_Depth[0]))\n",
    "bins_end_1   = np.int(np.max(Initiation_1_Actual_Depth[0]))\n",
    "# find the bins intervals and the bins frequencies\n",
    "(actual_N_1, bins_1, patches) = plt.hist(Initiation_1_Actual_Depth[0], bins_no,\\\n",
    "                                     range=(bins_start_1, bins_end_1),\\\n",
    "                                     histtype='step', normed=False, linewidth=2, color = 'blue',\\\n",
    "                                     label='Distribution of actual samples ILI_1_1');\n",
    "# find the bins intervals and the bins frequencies\n",
    "(detected_N, bins_1, patches1) = plt.hist(Cleaned_Measured_Depth_Simulated.Y_1_1[1:1642], bins_no,\\\n",
    "                                          range=(bins_start_1, bins_end_1),\\\n",
    "                                                 histtype='step', normed=False, linewidth=2, color = 'red',\\\n",
    "                                                 label='Distribution of estimated depth of detected pits');\n",
    "frequency_info_1.actual_N = actual_N_1\n",
    "frequency_info_1.detected_N = detected_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the number of reported pits given synthetic detected pits \n",
    "for i in range (1, bins_no+1):\n",
    "    POFC = np.exp(-(bins_1[i-1]+bins_1[i])/2/credible_pit_depth_threshold)  \n",
    "    frequency_info_1.reported_N[i] = frequency_info_1.detected_N[i]/(1-POFC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the distribution of R_1_1\n",
    "np.random.seed(seed_number)\n",
    "R_1_1 = pd.DataFrame(0, index = range(0, np.int(np.sum(frequency_info_1.reported_N))), columns = range(1)).astype(float) \n",
    "# Part of R_1_1 is equal to the truly detected pits\n",
    "for i in range(0, np.int(m_1)):\n",
    "    R_1_1[0][i] = Cleaned_Measured_Depth_Simulated.Y_1_1[i+1]\n",
    "jj = 0\n",
    "# for those bins that frequency of reported pits is higher than the detected pits, generate random number between lower and \n",
    "# upper bound of that bin\n",
    "for i in range(1, bins_no+1):      \n",
    "    if frequency_info_1.reported_N[i] > frequency_info_1.detected_N[i]:        \n",
    "        for j in range(1, np.int(frequency_info_1.reported_N[i] - frequency_info_1.detected_N[i])+1):          \n",
    "            R = np.random.uniform(bins_1[i-1], bins_1[i])\n",
    "            R_1_1[0][np.int(m_1) + jj] = R\n",
    "            jj = jj + 1     \n",
    "R_1_1.to_csv('R_1_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed_number)\n",
    "# Fliter true calls measurements from reported measurements\n",
    "Cleaned_Measured_Depth = pd.DataFrame(0, index = range(0, 5000), columns = range(4)).astype(float) \n",
    "Cleaned_Measured_Depth.columns = ['Y_1', 'Y_2', 'Y_3', 'Y_4']\n",
    "No_TrueCalled_Pits[0][1] = 0\n",
    "for item in R_1_1[0]:           \n",
    "    if np.random.uniform(0,1) > np.exp(-item/credible_pit_depth_threshold):         \n",
    "        Cleaned_Measured_Depth.Y_1[No_TrueCalled_Pits[0][1]] = item        \n",
    "        No_TrueCalled_Pits[0][1] = No_TrueCalled_Pits[0][1] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comapring histograms\n",
    "plt.figure(figsize=(12, 9))\n",
    "plt.xlabel('Pit Depth(mm)', fontsize = 20)\n",
    "plt.ylabel('PMF', fontsize = 20)\n",
    "plt.hist(R_1_1[0], bins_no, color = 'blue', range=(bins_start_1, bins_end_1), histtype='step', density=False, linewidth=2,\\\n",
    "         label='Reported measurements');  \n",
    "plt.hist(Cleaned_Measured_Depth.Y_1[0:No_TrueCalled_Pits[0][1]], bins_no, color = 'red', range=(bins_start_1, bins_end_1),\\\n",
    "         histtype='step', density=False, linewidth=1,\\\n",
    "         label='True Call measurements'); \n",
    "plt.xlim(bins_start_1, 30);\n",
    "\n",
    "plt.title('' , fontsize = 16)\n",
    "plt.legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-1-1 ILI_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_2_d is the Cleaned simulated measured depth at ILI_2\n",
    "Y_2_d = pd.DataFrame(pd.concat([Cleaned_Measured_Depth_Simulated.Y_2_1[0:No_Detected_Pits.loc[1][1]],\\\n",
    "                                         Cleaned_Measured_Depth_Simulated.Y_2_2[0:No_Detected_Pits.loc[1][4]]], axis=0,\\\n",
    "                                        join='outer', ignore_index=True, keys=None, levels=None, names=None,\\\n",
    "                                        verify_integrity=False, copy=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing the histograms and finding the bins intervals and frequencies\n",
    "frequency_info_2 = pd.DataFrame(0, index = range(1, bins_no+1), columns = range(6)).astype(float)\n",
    "frequency_info_2.columns = ['actual_N','detected_N', 'reported_N', 'estimated_N_WO_POD', 'estimated_N_W_POD',\\\n",
    "                            'rounded_estimated_N_W_POD']\n",
    "bins_start_2 = np.int(np.min(pd.concat([Initiation_2_Actual_Depth[0], Initiation_1_Actual_Depth[1]])))\n",
    "bins_end_2   = np.int(np.max(pd.concat([Initiation_2_Actual_Depth[0], Initiation_1_Actual_Depth[1]])))\n",
    "(actual_N_2, bins_2, patches) = plt.hist(pd.concat([Initiation_2_Actual_Depth[0], Initiation_1_Actual_Depth[1]]), bins_no,\\\n",
    "                                     range=(bins_start_2, bins_end_2),\\\n",
    "                                     histtype='step', normed=False, linewidth=2, color = 'blue',\\\n",
    "                                     label='Distribution of actual samples ILI_2')\n",
    "(detected_N_2, bins_2, patches2) = plt.hist(Y_2_d[0], bins_no, range=(bins_start_2, bins_end_2),\\\n",
    "                                                 histtype='step', normed=False, linewidth=2, color = 'red',\\\n",
    "                                                 label='Distribution of estimated depth of detected pits');\n",
    "\n",
    "\n",
    "frequency_info_2.detected_N = detected_N_2\n",
    "frequency_info_2.actual_N = actual_N_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the number of reported pits given synthetic detected pits\n",
    "for i in range (1, bins_no+1):\n",
    "    POFC = np.exp(-(bins_2[i-1]+bins_2[i])/2/credible_pit_depth_threshold)  \n",
    "    frequency_info_2.reported_N[i] = frequency_info_2.detected_N[i]/(1-POFC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate the actual depth of reported pits and find the distribution of R_2\n",
    "np.random.seed(seed_number)\n",
    "R_2 = pd.DataFrame(0, index = range(0, np.int(np.sum(frequency_info_2.reported_N))), columns = range(1)).astype(float) \n",
    "for i in range(0, np.int(m_2)):\n",
    "    R_2[0][i] = Y_2_d[0][i]\n",
    "# for those bins that frequency of reported pits is higher than the detected pits, generate random number between lower and \n",
    "# upper bound of that bin\n",
    "jj = 0\n",
    "for i in range(1, bins_no+1):      \n",
    "    if frequency_info_2.reported_N[i] > frequency_info_2.detected_N[i]:        \n",
    "        for j in range(1, np.int(frequency_info_2.reported_N[i] - frequency_info_2.detected_N[i])+1):          \n",
    "            R = np.random.uniform(bins_2[i-1], bins_2[i])\n",
    "            R_2[0][np.int(m_2) + jj] = R\n",
    "            jj = jj + 1     \n",
    "R_2.to_csv('R_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fliter true calls measurements from reported measurements\n",
    "np.random.seed(seed_number)\n",
    "# Filter false calls from reported data \n",
    "No_TrueCalled_Pits[1][1] = 0\n",
    "for item in R_2[0]:           \n",
    "    if np.random.uniform(0,1) > np.exp(-item/credible_pit_depth_threshold):\n",
    "        Cleaned_Measured_Depth.Y_2[No_TrueCalled_Pits[1][1]] = item\n",
    "        No_TrueCalled_Pits[1][1] = No_TrueCalled_Pits[1][1] + 1\n",
    "print(No_TrueCalled_Pits[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison\n",
    "plt.figure(figsize=(12, 9))\n",
    "plt.xlabel('Pit Depth', fontsize = 16)\n",
    "plt.ylabel('PDF', fontsize = 16)\n",
    "\n",
    "\n",
    "dd = pd.DataFrame(pd.concat([Initiation_1_Actual_Depth[1], Initiation_2_Actual_Depth[0]], axis=0,\\\n",
    "                                        join='outer', ignore_index=True, keys=None, levels=None, names=None,\\\n",
    "                                        verify_integrity=False, copy=True))\n",
    "plt.hist(dd[0], bins_no, color = 'green', range=(bins_start_2, bins_end_2),\\\n",
    "          histtype='step', density=True, linewidth=2, label='Actual depth at 1_1');\n",
    "plt.hist(Y_2_d[0], bins_no, color = 'red', range=(bins_start_2, bins_end_2), histtype='step', density=True, linewidth=2,\\\n",
    "         label='Detected');  \n",
    "plt.hist(R_2[0], bins_no, color = 'blue', range=(bins_start_2, bins_end_2), histtype='step', density=True, linewidth=2,\\\n",
    "         label='Reported');  \n",
    "plt.hist(Cleaned_Measured_Depth.Y_2[0:No_TrueCalled_Pits[1][1]], bins_no, color = 'yellow', range=(bins_start_2, bins_end_2),\\\n",
    "         histtype='step', density=True, linewidth=2,\\\n",
    "         label='TrueCalls'); \n",
    "plt.xlim(bins_start_1, bins_end_1);\n",
    "\n",
    "plt.title('Updating Hyper-parameters' , fontsize = 16)\n",
    "plt.legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-1-2 ILI_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_3_d is the Cleaned simulated measured depth at ILI_3\n",
    "Y_3_d = pd.DataFrame(pd.concat([Cleaned_Measured_Depth_Simulated.Y_3_1[0:No_Detected_Pits.loc[1][2]],\\\n",
    "                                Cleaned_Measured_Depth_Simulated.Y_3_2[0:No_Detected_Pits.loc[1][5]],\\\n",
    "                                Cleaned_Measured_Depth_Simulated.Y_3_3[0:No_Detected_Pits.loc[1][7]]], axis=0,\\\n",
    "                                        join='outer', ignore_index=True, keys=None, levels=None, names=None,\\\n",
    "                                        verify_integrity=False, copy=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing the histograms and finding the bins intervals and frequencies\n",
    "frequency_info_3 = pd.DataFrame(0, index = range(1, bins_no+1), columns = range(6)).astype(float)\n",
    "frequency_info_3.columns = ['actual_N','detected_N', 'reported_N', 'estimated_N_WO_POD', 'estimated_N_W_POD',\\\n",
    "                            'rounded_estimated_N_W_POD']\n",
    "\n",
    "bins_start_3 = np.int(np.min(pd.concat([Initiation_3_Actual_Depth[0],Initiation_2_Actual_Depth[1], Initiation_1_Actual_Depth[2]])))\n",
    "bins_end_3   = np.int(np.max(pd.concat([Initiation_3_Actual_Depth[0],Initiation_2_Actual_Depth[1], Initiation_1_Actual_Depth[2]])))\n",
    "(actual_N_3, bins_3, patches) = plt.hist(pd.concat([Initiation_3_Actual_Depth[0],Initiation_2_Actual_Depth[1], Initiation_1_Actual_Depth[2]]), bins_no,\\\n",
    "                                     range=(bins_start_3, bins_end_3),\\\n",
    "                                     histtype='step', normed=False, linewidth=2, color = 'blue',\\\n",
    "                                     label='Distribution of actual samples ILI_3')\n",
    "(detected_N_3, bins_3, patches3) = plt.hist(Y_3_d[0], bins_no, range=(bins_start_3, bins_end_3),\\\n",
    "                                                 histtype='step', normed=False, linewidth=2, color = 'red',\\\n",
    "                                                 label='Distribution of estimated depth of detected pits');\n",
    "\n",
    "\n",
    "frequency_info_3.detected_N = detected_N_3\n",
    "frequency_info_3.actual_N = actual_N_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the number of reported pits given synthetic detected pits\n",
    "for i in range (1, bins_no+1):\n",
    "    POFC = np.exp(-(bins_3[i-1]+bins_3[i])/2/credible_pit_depth_threshold)  \n",
    "    frequency_info_3.reported_N[i] = frequency_info_3.detected_N[i]/(1-POFC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate the actual depth of reported pits and find the distribution of R_3\n",
    "np.random.seed(seed_number)\n",
    "R_3 = pd.DataFrame(0, index = range(0, np.int(np.sum(frequency_info_3.reported_N))), columns = range(1)).astype(float) \n",
    "for i in range(0, np.int(m_3)):\n",
    "    R_3[0][i] = Y_3_d[0][i]\n",
    "jj = 0\n",
    "for i in range(1, bins_no+1):      \n",
    "    if frequency_info_3.reported_N[i] > frequency_info_3.detected_N[i]:        \n",
    "        for j in range(1, np.int(frequency_info_3.reported_N[i] - frequency_info_3.detected_N[i])+1):          \n",
    "            R = np.random.uniform(bins_3[i-1], bins_3[i])\n",
    "            R_3[0][np.int(m_3) + jj] = R\n",
    "            jj = jj + 1     \n",
    "R_3.to_csv('R_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fliter true calls measurements from reported measurements\n",
    "np.random.seed(seed_number)\n",
    "No_TrueCalled_Pits[2][1] = 0\n",
    "for item in R_3[0]:           \n",
    "    if np.random.uniform(0,1) > np.exp(-item/credible_pit_depth_threshold):\n",
    "        Cleaned_Measured_Depth.Y_3[No_TrueCalled_Pits[2][1]] = item\n",
    "        No_TrueCalled_Pits[2][1] = No_TrueCalled_Pits[2][1] + 1\n",
    "print(No_TrueCalled_Pits[2][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison\n",
    "plt.figure(figsize=(12, 9))\n",
    "plt.xlabel('Pit Depth', fontsize = 16)\n",
    "plt.ylabel('PDF', fontsize = 16)\n",
    "\n",
    "\n",
    "ddd = pd.DataFrame(pd.concat([Initiation_1_Actual_Depth[2],\\\n",
    "                              Initiation_2_Actual_Depth[1],\\\n",
    "                              Initiation_3_Actual_Depth[0]],axis=0,\\\n",
    "                            join='outer', ignore_index=True, keys=None, levels=None, names=None,\\\n",
    "                             verify_integrity=False, copy=True))\n",
    "plt.hist(ddd[0], bins_no, color = 'green', range=(bins_start_3, bins_end_3),\\\n",
    "          histtype='step', density=True, linewidth=2, label='Actual depth at 1_1');\n",
    "plt.hist(Y_3_d[0], bins_no, color = 'red', range=(bins_start_3, bins_end_3), histtype='step', density=True, linewidth=2,\\\n",
    "         label='Detected');  \n",
    "plt.hist(R_3[0], bins_no, color = 'blue', range=(bins_start_3, bins_end_3), histtype='step', density=True, linewidth=2,\\\n",
    "         label='Reported');  \n",
    "plt.hist(Cleaned_Measured_Depth.Y_3[0:No_TrueCalled_Pits[2][1]], bins_no, color = 'yellow', range=(bins_start_3, bins_end_3),\\\n",
    "         histtype='step', density=True, linewidth=2,\\\n",
    "         label='TrueCalls'); \n",
    "plt.xlim(bins_start_3, bins_end_3);\n",
    "\n",
    "plt.title('Updating Hyper-parameters' , fontsize = 16)\n",
    "plt.legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cleaned_Measured_Depth.to_csv('Cleaned_Measured_Depth.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "No_TrueCalled_Pits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "No_TrueCalled_Pits[2][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3- Using ILI 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-1- Estimated D_1 , k , nu and Scale Par in Openbugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Cleaned_Measured_Depth.Y_1_1 as the first set of ILI data to estimate the hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_1_1_actual = k*(ILI_info.ILI_time[0]-0)**nu\n",
    "alpha_1_1_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimated parameters at ILI_1 by OpenBUGS using true calls data at ILI_1\n",
    "k_1  = 0.4836\n",
    "nu_1 = 0.3896\n",
    "ScalePar_1 = 3.054\n",
    "alpha_1_1_OpenBugs = 1.504\n",
    "alpha_1_1_Est = k_1*(ILI_info.ILI_time[0]-0)**nu_1\n",
    "alpha_1_1_Est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimated actual depth by OpenBUGS for detected pits at ILI \n",
    "D_1_1 = pd.read_excel('D.xlsx', sheetname='D_1_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-2- Estimate the number of actual pits and their actual depth at  t_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing the number of pits at each bin of the PMF of the actual depth and the estimated depth without POD\n",
    "\n",
    "\n",
    "(estimated_N_WO_POD_1, bins_1, patches1) = plt.hist(D_1_1['depth'], bins_no, range=(bins_start_1, bins_end_1),\\\n",
    "                                                 histtype='step', density=False, linewidth=2, color = 'red',\\\n",
    "                                                 label='Distribution of estimated depth of detected pits');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculating number of pits at each bin of the PMF of the estimated depth without POD\n",
    "(estimated_N_WO_POD_1, bins_1, patches1) = plt.hist(D_1_1['depth'], bins_no, \\\n",
    "                                                 histtype='step', density=False, linewidth=2, color = 'red',\\\n",
    "                                                 label='Distribution of estimated depth of detected pits');\n",
    "frequency_info_1.estimated_N_WO_POD = estimated_N_WO_POD_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the number of actual pits (M_1_1) given the number of truly detected pits (m_1) at ILI_1:\n",
    "for i in range (1, bins_no+1):\n",
    "    POD = 1-np.exp(-(bins_1[i-1]+bins_1[i])/2/detection_threshold)\n",
    "    frequency_info_1.estimated_N_W_POD[i] = frequency_info_1.estimated_N_WO_POD[i]/POD\n",
    "frequency_info_1.rounded_estimated_N_W_POD = np.round(frequency_info_1.estimated_N_W_POD, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_info_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "p = figure(title = 'Comparison between actual and estimated number of pits at each bin', x_axis_label='actual_N',\\\n",
    "           y_axis_label='rounded_estimated_N_W_POD', plot_height = 700, plot_width = 700)   \n",
    "p.scatter(actual_N_1, frequency_info_1.rounded_estimated_N_W_POD, line_width = 2, color = 'blue')\n",
    "p.line([0, np.max(actual_N_1)], [0, np.max(actual_N_1)], line_width = 2, legend ='1 X 1 line', color = 'red')\n",
    "p.legend.location = \"top_left\"\n",
    "show(p) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_1_1 = np.int(np.sum(frequency_info_1.estimated_N_WO_POD))\n",
    "m_1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_1_1= np.int(np.sum(frequency_info_1.rounded_estimated_N_W_POD))\n",
    "M_1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate the actual depth of undetected pits and find the distribution of X_1\n",
    "np.random.seed(seed_number)\n",
    "X_1 = pd.DataFrame(0, index = range(0, M_1_1), columns = range(1)).astype(float) \n",
    "for i in range(0, m_1_1):\n",
    "    X_1[0][i] = D_1_1['depth'][i]\n",
    "\n",
    "jj = 0\n",
    "for i in range(1, bins_no+1):      \n",
    "    if frequency_info_1.rounded_estimated_N_W_POD[i] > frequency_info_1.estimated_N_WO_POD[i]:        \n",
    "        for j in range(1, np.int(frequency_info_1.rounded_estimated_N_W_POD[i] - frequency_info_1.estimated_N_WO_POD[i])+1):          \n",
    "            X = np.random.uniform(bins_1[i-1], bins_1[i])\n",
    "            X_1[0][m_1_1 + jj] = X\n",
    "            jj = jj + 1     \n",
    "X_1.to_csv('X_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 9))\n",
    "plt.xlabel('Pit Depth(mm)', fontsize = 20)\n",
    "plt.ylabel('PMF', fontsize = 20)\n",
    "bins_start_X_1 = np.int(np.min([np.min(Initiation_1_Actual_Depth[0]), np.min(X_1[0])]))\n",
    "bins_end_X_1   = np.int(np.max([np.max(Initiation_1_Actual_Depth[0]), np.max(X_1[0])]))\n",
    "plt.hist(Initiation_1_Actual_Depth[0], bins_no, color = 'green', range=(bins_start_X_1, bins_end_X_1),\\\n",
    "         histtype='step', density=True, linewidth=2, label='Simulated actual depth (X_1) at t_1');\n",
    "plt.hist(X_1[0], bins_no, color = 'red', range=(bins_start_X_1, bins_end_X_1), histtype='step', density=True, linewidth=1,\\\n",
    "         label='Estimated actual depth (X_1) at t_1')  \n",
    "plt.xlim(bins_start_X_1, 30)\n",
    "plt.title('' , fontsize = 16)\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(actual_N_1, bins_1, patches) = plt.hist(Initiation_1_Actual_Depth[0], bins_no,\\\n",
    "                                     range=(bins_start_X_1, bins_end_X_1),\\\n",
    "                                     histtype='step', density=False, linewidth=2, color = 'blue',\\\n",
    "                                     label='Distribution of actual samples ILI_1_1');\n",
    "(estimated_N_W_POD_1, bins_1, patches1) = plt.hist(X_1[0], bins_no, range=(bins_start_X_1, bins_end_X_1),\\\n",
    "                                                 histtype='step', density=False, linewidth=2, color = 'red',\\\n",
    "                                                 label='Distribution of estimated depth of detected pits');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KL_divergences(h1_bin_freq, h2_bin_freq, bins):\n",
    "    D_KL = 0\n",
    "    for i in range(0, bins):\n",
    "        if h2_bin_freq[i] > 0 and h1_bin_freq[i] > 0:\n",
    "            D_KL += h1_bin_freq[i]*np.log(h1_bin_freq[i]/h2_bin_freq[i])\n",
    "    return D_KL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_Actual_1 = pd.concat([Initiation_1_Actual_Depth[0]]).shape[0]\n",
    "N_Estimated_1 = X_1.shape[0] \n",
    "KLD1 = KL_divergences(actual_N_1/N_Actual_1, estimated_N_WO_POD_1/N_Estimated_1, bins_no)\n",
    "KLD1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SKLD1 = (KL_divergences(actual_N_1/N_Actual_1, estimated_N_WO_POD_1/N_Estimated_1, bins_no) + \\\n",
    "         KL_divergences(estimated_N_WO_POD_1/N_Estimated_1, actual_N_1/N_Actual_1, bins_no))/2\n",
    "SKLD1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ChiSq_1 = 0\n",
    "for i in range(0, bins_no):\n",
    "    if actual_N_1[i] > 0 or estimated_N_W_POD_1[i] > 0:\n",
    "        ChiSq_1 = ChiSq_1 + (actual_N_1[i]/N_Actual_1 - estimated_N_W_POD_1[i]/N_Estimated_1)**2/\\\n",
    "        (actual_N_1[i]/N_Actual_1 + estimated_N_W_POD_1[i]/N_Estimated_1)\n",
    "ChiSq_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4- Using ILI 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4-1- Cluster the ILI_2 measurement data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimated shape parameter at ILI 2 for pits that are initiated before ILI 1\n",
    "alpha_prime_2_1 = k_1 * (ILI_info.ILI_time[1] - 0) ** nu_1\n",
    "alpha_prime_2_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_2_1_actual = k*(ILI_info.ILI_time[1]-0)**nu\n",
    "alpha_2_1_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_2_2_actual = k*(ILI_info.ILI_time[1]-ILI_info.ILI_time[0])**nu\n",
    "alpha_2_2_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ScalePar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimated shape parameter at ILI 2 for pits that are initiated between ILI 1 and 2\n",
    "alpha_prime_2_2 = k_1 * (ILI_info.ILI_time[1] - ILI_info.ILI_time[0]) ** nu_1\n",
    "alpha_prime_2_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ScalePar_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Wolfram Alpha to calculate m_prime_2_1\n",
    "# WolframAlpha equation: \n",
    "# integrate 1870/gamma(1.932)/3.054^1.932*x^(1.932-1)*exp(-x/3.054)*(1-exp(-x/0.84))dx from x=0 to 20\n",
    "m_prime_2_1 = 1755 # = _1_1 _2_1(x)()()\n",
    "m_prime_2_2 = m_2 - m_prime_2_1\n",
    "m_prime_2_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed_number)\n",
    "# Estimate the expected distribution of measuremnets at t_2\n",
    "# For ILI_2_1\n",
    "Y_prime_2_1 = pd.DataFrame(np.zeros(1))\n",
    "D_prime_2_1 = np.random.gamma(alpha_prime_2_1, scale = ScalePar_1, size=m_prime_2_1) \n",
    "\n",
    "j = 0\n",
    "for i in range (0, m_prime_2_1):\n",
    "    Y_prime_2_1.loc[j] = a_ILI + b_ILI * D_prime_2_1[i] + np.random.normal (0, ILI_error_STD)  \n",
    "    j = j + 1\n",
    "mean_Y_prime_2_1 = np.mean(Y_prime_2_1)\n",
    "STD_Y_prime_2_1  = np.std(Y_prime_2_1)\n",
    "\n",
    "# For ILI_2_2\n",
    "Y_prime_2_2 = pd.DataFrame(np.zeros(1))\n",
    "D_prime_2_2 = np.random.gamma(alpha_prime_2_2, scale=ScalePar_1, size=m_prime_2_2[1]) \n",
    "\n",
    "j = 0\n",
    "for i in range (0, m_prime_2_2[1]):\n",
    "    Y_prime_2_2.loc[j] = a_ILI + b_ILI * D_prime_2_2[i] + np.random.normal (0, ILI_error_STD)  \n",
    "    j = j + 1\n",
    "mean_Y_prime_2_2 = np.mean(Y_prime_2_2)\n",
    "STD_Y_prime_2_2 = np.std(Y_prime_2_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of expected measured data at ILI_2\n",
    "tt = np.linspace(-10, 50, 1000)\n",
    "plt.figure(figsize=(12, 9))\n",
    "plt.xlabel('Pit Depth', fontsize = 16)\n",
    "plt.ylabel('PDF', fontsize = 16)\n",
    "plt.plot(tt, norm.pdf(tt, loc = mean_Y_prime_2_1, scale = STD_Y_prime_2_1), c='green', linestyle='--', alpha=0.5,  linewidth=3,\\\n",
    "         label='y_prime_ILI_2_1') \n",
    "\n",
    "plt.plot(tt, norm.pdf(tt, loc = mean_Y_prime_2_2, scale =  STD_Y_prime_2_2), c='Orange', linestyle='--', alpha=0.5,  linewidth=3,\\\n",
    "          label='y_prime_ILI_2_2')\n",
    "\n",
    "plt.xlim([-10, 20]);\n",
    "plt.title('' , fontsize = 16)\n",
    "plt.legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine detected measurements at those pits that are detected at t_2 and initiated at 1st and 2nd intervals\n",
    "Y_2_with_zeros = pd.DataFrame(Cleaned_Measured_Depth.Y_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove zeros from Y_2_with_zeros and save them in an array\n",
    "Y_2_array = pd.DataFrame(np.zeros(1))\n",
    "j = 0\n",
    "for i in range (0, Cleaned_Measured_Depth.Y_2.shape[0]):       \n",
    "    if Y_2_with_zeros.Y_2[i] > 0 or Y_2_with_zeros.Y_2[i] < 0:\n",
    "        Y_2_array.loc[j] = Y_2_with_zeros.Y_2[i] \n",
    "        j = j + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figureing out which detected pit at t_2 belongs to which population 2_1 or 2_2\n",
    "Y_2 = pd.DataFrame(0, index = range(0, len(Y_2_array)), columns = range(6)).astype(float) \n",
    "Y_2.columns = ['measurement', 'Pr_yi_given_2_1', 'Pr_yi_given_2_2','Pr_2_1_given_yi', 'Pr_2_2_given_yi',\\\n",
    "               'cluster_index']\n",
    "Y_2.measurement = Y_2_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the start and end points of the bins of Y_2 which will be the same for Y_2_1 and Y_2_2 as well\n",
    "measurement_bins_start_2 = np.int(np.min(Y_2.measurement))\n",
    "measurement_bins_end_2   = np.int(np.max(Y_2.measurement))\n",
    "(measurement_N_2, measurement_bins_2, patches) = plt.hist(Y_2.measurement, bins_no,\\\n",
    "                                     range=(measurement_bins_start_2, measurement_bins_end_2),\\\n",
    "                                     histtype='step', density=False, linewidth=2, color = 'blue',\\\n",
    "                                     label='');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the frequency of each bin for Y_prime_2_1 using the same start and end bin as Y_2\n",
    "(Y_prime_2_1_N, measurement_bins_2, patches) = plt.hist(Y_prime_2_1[0], bins_no,\\\n",
    "                                     range=(measurement_bins_start_2, measurement_bins_end_2),\\\n",
    "                                     histtype='step', density=False, linewidth=2, color = 'blue',\\\n",
    "                                     label='Y_prime_2_1');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the frequency of each bin for Y_prime_2_1 using the same start and end bin as Y_2\n",
    "(Y_prime_2_2_N, measurement_bins_2, patches) = plt.hist(Y_prime_2_2[0], bins_no,\\\n",
    "                                     range=(measurement_bins_start_2, measurement_bins_end_2),\\\n",
    "                                     histtype='step', density=False, linewidth=2, color = 'red',\\\n",
    "                                     label='Y_prime_2_2');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figureing out which detected pit at t_2 belongs to which population 2_1 or 2_2 \n",
    "Y_2_1_bins_freq = pd.DataFrame(0, index = range(0, bins_no), columns = range(1)).astype(int) \n",
    "Y_2_2_bins_freq = pd.DataFrame(0, index = range(0, bins_no), columns = range(1)).astype(int) \n",
    "\n",
    "expected_bin_no_2_1 = pd.DataFrame(0, index = range(0, bins_no), columns = range(1)).astype(int) \n",
    "expected_bin_no_2_2 = pd.DataFrame(0, index = range(0, bins_no), columns = range(1)).astype(int) \n",
    "\n",
    "bin_index_2 = pd.DataFrame(np.zeros(len(Y_2_array))).astype(int)\n",
    "\n",
    "Y_prime_2_1_No = 0\n",
    "Y_prime_2_2_No = 0\n",
    "\n",
    "\n",
    "# identifying the bin index for each measured value\n",
    "for i in range(0, len(Y_2_array)):    \n",
    "    for j in range(0, bins_no):\n",
    "        if Y_2.measurement[i] > measurement_bins_2[j] and Y_2.measurement[i] < measurement_bins_2[j+1]:\n",
    "            bin_index_2.iloc[i] = np.int(j)\n",
    "            break    \n",
    "\n",
    "for i in range(0, len(Y_2_array)):     \n",
    "    if Y_2_1_bins_freq[0][bin_index_2[0][i]] < Y_prime_2_1_N[bin_index_2[0][i]]:            \n",
    "            Y_2.cluster_index[i] = 1\n",
    "            Y_2_1_bins_freq[0][bin_index_2[0][i]] = Y_2_1_bins_freq[0][bin_index_2[0][i]] + 1\n",
    "            Y_prime_2_1_No = Y_prime_2_1_No + 1\n",
    "    else:\n",
    "        Y_2.cluster_index[i] = 2\n",
    "        Y_2_2_bins_freq[0][bin_index_2[0][i]] = Y_2_2_bins_freq[0][bin_index_2[0][i]] + 1\n",
    "        Y_prime_2_2_No = Y_prime_2_2_No + 1     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the arrays of Y_2_1 and Y_2_2\n",
    "Y_2_1 = pd.DataFrame(0, index = range(1, Y_prime_2_1_No+1), columns = range(1)).astype(float)\n",
    "Y_2_2 = pd.DataFrame(0, index = range(1, Y_prime_2_2_No+1), columns = range(1)).astype(float)\n",
    "j1 = 1\n",
    "j2 = 1\n",
    "for i in range (0, len(Y_2_array)): \n",
    "    if Y_2.cluster_index[i] == 1:\n",
    "        Y_2_1[0][j1] = Y_2.measurement[i]  \n",
    "        j1 = j1 + 1\n",
    "    elif Y_2.cluster_index[i] == 2:\n",
    "        Y_2_2[0][j2] = Y_2.measurement[i]  \n",
    "        j2 = j2 + 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_2.to_csv('Y_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y_2_1.to_csv('Y_2_1.csv')\n",
    "Y_2_2.to_csv('Y_2_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4-2- Use the Clustered ILI_2 measurement data to update the hyper-parameters and estimate the actual depth of the detected pits in OpenBUGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual shape parameter at ILI 2 for pits that are initiated before ILI 1\n",
    "alpha_2_1_actual = k * (ILI_info.ILI_time[1] - 0) ** nu\n",
    "alpha_2_1_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual shape parameter at ILI 2 for pits that are initiated between ILI 1 and ILI 2\n",
    "alpha_2_2_actual = k * (ILI_info.ILI_time[1] - ILI_info.ILI_time[0]) ** nu\n",
    "alpha_2_2_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimated parameters at ILI 2 by OpenBUGS at t_2\n",
    "k_2  = 0.5919\n",
    "nu_2 = 0.3115\n",
    "ScalePar_2 = 2.983\n",
    "alpha_2_1_Est = 1.787\n",
    "alpha_2_2_Est = 0.9753"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimated actual depth by OpenBUGS for detected pits at ILI \n",
    "#D_2_1 = pd.read_excel('D.xlsx', sheetname='D_2_1')\n",
    "#D_2_2 = pd.read_excel('D.xlsx', sheetname='D_2_2')\n",
    "D_2 = pd.read_excel('D.xlsx', sheetname='D_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = figure(title = 'Comparison between actual and estimated number of pits at each bin', x_axis_label='actual_N',\\\n",
    "           y_axis_label='rounded_estimated_N_W_POD', plot_height = 700, plot_width = 700)   \n",
    "p.line( tt, k*(tt-t0)**nu*ScalePar, line_width = 2, legend ='actual',  color = 'red')\n",
    "p.line( tt, k_1*(tt-t0)**nu_1*ScalePar_1, line_width = 2, legend ='Estimated 1', color = 'blue')\n",
    "p.line( tt, k_2*(tt-t0)**nu_2*ScalePar_2, line_width = 2, legend ='Estimated 2', color = 'green')\n",
    "\n",
    "p.legend.location = \"top_left\"\n",
    "\n",
    "show(p) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4-3- Estimate the number of actual pits and their actual depth at  t_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating number of pits at each bin of the PMF of actual depth and estimated depth without POD\n",
    "(estimated_N_WO_POD_2, bins_2, patches2) = plt.hist(D_2['depth'], bins_no, \\\n",
    "                                                 histtype='step', density=False, linewidth=2, color = 'red',\\\n",
    "                                                 label='Distribution of estimated depth of detected pits');\n",
    "frequency_info_2.estimated_N_WO_POD = estimated_N_WO_POD_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the number of actual pits (M_2) given the number of truly detected pits (m_2) at ILI_2:\n",
    "for i in range (1, bins_no+1):\n",
    "    POD = 1-np.exp(-(bins_2[i-1]+bins_2[i])/2/detection_threshold)\n",
    "    frequency_info_2.estimated_N_W_POD[i] = frequency_info_2.estimated_N_WO_POD[i]/POD\n",
    "frequency_info_2.rounded_estimated_N_W_POD = np.round(frequency_info_2.estimated_N_W_POD, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_info_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimated number of existing pits at t_2\n",
    "M_2 = np.int(np.sum(frequency_info_2.rounded_estimated_N_W_POD))\n",
    "M_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_2-No_TrueCalled_Pits[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed_number)\n",
    "# Find the PMF of X_2\n",
    "X_2 = pd.DataFrame(0, index = range(0, M_2), columns = range(1)).astype(float) \n",
    "for i in range(0, No_TrueCalled_Pits[1][1]): # change this to m_2\n",
    "    X_2[0][i] = D_2['depth'][i]\n",
    "# estimate the actual depth of undetected pits and find the distribution of X_2\n",
    "\n",
    "jj = 0\n",
    "for i in range(1, bins_no+1):      \n",
    "    if frequency_info_2.rounded_estimated_N_W_POD[i] > frequency_info_2.estimated_N_WO_POD[i]:        \n",
    "        for j in range(1, np.int(frequency_info_2.rounded_estimated_N_W_POD[i] - frequency_info_2.estimated_N_WO_POD[i])+1):          \n",
    "            X = np.random.uniform(bins_2[i-1], bins_2[i])\n",
    "            X_2[0][No_TrueCalled_Pits[1][1] + jj] = X # change this to m_2\n",
    "            jj = jj + 1     \n",
    "X_2.to_csv('X_2.csv')\n",
    "print(jj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual comparison between actual and estimated depth for X_2\n",
    "plt.figure(figsize=(12, 9))\n",
    "plt.xlabel('Pit Depth (mm)', fontsize = 20)\n",
    "plt.ylabel('PMF', fontsize = 20)\n",
    "bins_start_X_2 = np.int(np.min([np.min(pd.concat([Initiation_2_Actual_Depth[0], Initiation_1_Actual_Depth[1]])),\\\n",
    "                              np.min(X_2[0])]))\n",
    "bins_end_X_2   = np.int(np.max([np.max(pd.concat([Initiation_2_Actual_Depth[0], Initiation_1_Actual_Depth[1]])),\\\n",
    "                              np.max(X_2[0])]))\n",
    "plt.hist(pd.concat([Initiation_2_Actual_Depth[0], Initiation_1_Actual_Depth[1]]), bins_no, color = 'green',\\\n",
    "         range=(bins_start_X_2, bins_end_X_2), histtype='step', density=True, linewidth=2,\\\n",
    "         label='Simulated actual depth (X_2) at t_2');\n",
    "plt.hist(X_2[0], bins_no, color = 'red', range=(bins_start_X_2, bins_end_X_2), histtype='step', density=True,\\\n",
    "         linewidth=1, label='Estimated actual depth (X_2) at t_2');\n",
    "\n",
    "plt.xlim([bins_start_X_2, 30]);\n",
    "plt.title('' , fontsize = 16)\n",
    "plt.legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(actual_N_2, bins_2, patches) = plt.hist(pd.concat([Initiation_2_Actual_Depth[0], Initiation_1_Actual_Depth[1]]),\\\n",
    "                                         bins_no, range=(bins_start_X_2, bins_end_X_2),\\\n",
    "                                     histtype='step', density=False, linewidth=2, color = 'blue',\\\n",
    "                                     label='Distribution of actual samples ILI_2');\n",
    "(estimated_N_W_POD_2, bins_2, patches2) = plt.hist(X_2[0], bins_no, range=(bins_start_X_2, bins_end_X_2),\\\n",
    "                                                 histtype='step', density=False, linewidth=2, color = 'red',\\\n",
    "                                                 label='Distribution of estimated depth of detected pits');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_Actual_2 = pd.concat([Initiation_2_Actual_Depth[0], Initiation_1_Actual_Depth[1]]).shape[0]\n",
    "N_Estimated_2 = X_2.shape[0] \n",
    "KLD2 = KL_divergences(actual_N_2/N_Actual_2, estimated_N_WO_POD_2/N_Estimated_2, bins_no)\n",
    "KLD2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SKLD2 = (KL_divergences(actual_N_2/N_Actual_2, estimated_N_WO_POD_2/N_Estimated_2, bins_no) + \\\n",
    "         KL_divergences(estimated_N_WO_POD_2/N_Estimated_2, actual_N_2/N_Actual_2, bins_no))/2\n",
    "SKLD2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ChiSq_2 = 0\n",
    "for i in range(0, bins_no):\n",
    "    if actual_N_2[i] > 0 or estimated_N_W_POD_2[i] > 0:\n",
    "        ChiSq_2 = ChiSq_2 + (actual_N_2[i]/N_Actual_2 - estimated_N_W_POD_2[i]/N_Estimated_2)**2/\\\n",
    "        (actual_N_2[i]/N_Actual_2 + estimated_N_W_POD_2[i]/N_Estimated_2)\n",
    "ChiSq_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5- Using ILI 3 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5-1- Cluster the ILI_3 measurement data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimated shape parameter at ILI 3 for pits that are initiated before ILI 1\n",
    "alpha_prime_3_1 = k_2 * (ILI_info.ILI_time[2] - 0) ** nu_2\n",
    "alpha_prime_3_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_3_1_actual = k * (ILI_info.ILI_time[2] - 0) ** nu\n",
    "alpha_3_1_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimated shape parameter at ILI 3 for pits that are initiated between ILI 1 and 2\n",
    "alpha_prime_3_2 = k_2 * (ILI_info.ILI_time[2] - ILI_info.ILI_time[0]) ** nu_2\n",
    "alpha_prime_3_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_3_2_actual = k * (ILI_info.ILI_time[2] - ILI_info.ILI_time[0]) ** nu\n",
    "alpha_3_2_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimated shape parameter at ILI 3 for pits that are initiated between ILI 2 and 3\n",
    "alpha_prime_3_3 = k_2 * (ILI_info.ILI_time[2] - ILI_info.ILI_time[1]) ** nu_2\n",
    "alpha_prime_3_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_3_3_actual = k * (ILI_info.ILI_time[2] - ILI_info.ILI_time[1]) ** nu\n",
    "alpha_3_3_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_2-_1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ScalePar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ScalePar_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Wolfram Alpha to calculate m_prime_3_3\n",
    "# = _1_1 _3_1(x)()(), _3_1(x) = gamma(alpha_prime_3_1, ScalePar_1) = \n",
    "# integrate 1870/gamma(1.8676)/2.983^1.8676*x^(1.8676-1)*exp(-x/2.983)*(1-exp(-x/0.84))dx from x=0 to 20\n",
    "m_prime_3_1 = 1745 \n",
    "# integrate 464/gamma(0.779)/1.765^0.779*x^(0.779-1)*exp(-x/1.765)*(1-exp(-x/0.84))dx from x=0 to 20\n",
    "m_prime_3_2 = 346 # = (M_2-_1_1) _3_2(x)()(), _3_2(x) = gamma(alpha_prime_3_2, ScalePar_2)\n",
    "m_prime_3_3 = m_3 - m_prime_3_1 - m_prime_3_2\n",
    "m_prime_3_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 9))\n",
    "plt.xlabel('Pit Depth', fontsize = 16)\n",
    "plt.ylabel('PDF', fontsize = 16)\n",
    "plt.plot(tt, gamma.pdf(tt, alpha_3_1_actual, scale = ScalePar), c='green', linestyle='--', alpha=0.5,  linewidth=3,\\\n",
    "         label='Actual pit depth dist.') \n",
    "\n",
    "plt.plot(tt, gamma.pdf(tt, alpha_prime_3_1, scale = ScalePar_1), c='Orange', linestyle='--', alpha=0.5,  linewidth=3,\\\n",
    "          label='Estimated pit depth dist.')\n",
    "\n",
    "plt.title('' , fontsize = 16)\n",
    "plt.legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_3_with_zeros = pd.DataFrame(Cleaned_Measured_Depth.Y_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove zeros from Y_3_with_zeros\n",
    "Y_3_array = pd.DataFrame(np.zeros(1)).astype(float)\n",
    "j = 0\n",
    "for i in range (0, Cleaned_Measured_Depth.Y_3.shape[0]):       \n",
    "    if Y_3_with_zeros.Y_3[i] > 0 or Y_3_with_zeros.Y_3[i] < 0:\n",
    "        Y_3_array.loc[j] = Y_3_with_zeros.Y_3[i]  \n",
    "        j = j + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the ILI 3 cleaned data in one new file Y_3 for clustering\n",
    "Y_3 = pd.DataFrame(0, index = range(0, len(Y_3_array)), columns = range(8)).astype(float) \n",
    "Y_3.columns = ['measurement', 'Pr_yi_given_3_1', 'Pr_yi_given_3_2','Pr_yi_given_3_3','Pr_3_1_given_yi',\\\n",
    "               'Pr_3_2_given_yi', 'Pr_3_3_given_yi', 'cluster_index']\n",
    "Y_3.measurement = Y_3_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the start and end points of the bins of Y_3 which will be the same for Y_3_1, Y_3_2, and Y_3_3 as well\n",
    "measurement_bins_start_3 = np.int(np.min(Y_3.measurement))\n",
    "measurement_bins_end_3   = np.int(np.max(Y_3.measurement))\n",
    "(measurement_N_3, measurement_bins_3, patches) = plt.hist(Y_3.measurement, bins_no,\\\n",
    "                                     range=(measurement_bins_start_3, measurement_bins_end_3),\\\n",
    "                                     histtype='step', density=False, linewidth=2, color = 'blue',\\\n",
    "                                     label='Y_3');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed_number)\n",
    "# Estimate the expected distribution of measuremnets at t_3\n",
    "# For ILI_3_1\n",
    "Y_prime_3_1 = pd.DataFrame(np.zeros(1))\n",
    "D_prime_3_1 = np.random.gamma(alpha_prime_3_1, scale = ScalePar_2, size = m_prime_3_1) \n",
    "\n",
    "j = 0\n",
    "for i in range (0, np.int(m_prime_3_1)):\n",
    "    Y_prime_3_1.loc[j] = a_ILI + b_ILI * D_prime_3_1[i] + np.random.normal (0, ILI_error_STD)  \n",
    "    j = j + 1\n",
    "mean_Y_prime_3_1 = np.mean(Y_prime_3_1)\n",
    "STD_Y_prime_3_1 = np.std(Y_prime_3_1)\n",
    "\n",
    "# For ILI_3_2\n",
    "Y_prime_3_2 = pd.DataFrame(np.zeros(1))\n",
    "D_prime_3_2 = np.random.gamma(alpha_prime_3_2, scale = ScalePar_2, size = m_prime_3_2) \n",
    "\n",
    "j = 0\n",
    "for i in range (0, np.int(m_prime_3_2)):\n",
    "    Y_prime_3_2.loc[j] = a_ILI + b_ILI * D_prime_3_2[i] + np.random.normal (0, ILI_error_STD)  \n",
    "    j = j + 1\n",
    "mean_Y_prime_3_2 = np.mean(Y_prime_3_2)\n",
    "STD_Y_prime_3_2 = np.std(Y_prime_3_2)\n",
    "\n",
    "# For ILI_3_3\n",
    "Y_prime_3_3 = pd.DataFrame(np.zeros(1))\n",
    "D_prime_3_3 = np.random.gamma(alpha_prime_3_3, scale = ScalePar_2, size = m_prime_3_3[1]) \n",
    "\n",
    "j = 0\n",
    "for i in range (0, np.int(m_prime_3_3)):\n",
    "    Y_prime_3_3.loc[j] = a_ILI + b_ILI * D_prime_3_3[i] + np.random.normal (0, ILI_error_STD)  \n",
    "    j = j + 1\n",
    "mean_Y_prime_3_3 = np.mean(Y_prime_3_3)\n",
    "STD_Y_prime_3_3 = np.std(Y_prime_3_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual comparison between actual and clustered measurements\n",
    "plt.figure(figsize=(12, 9))\n",
    "plt.xlabel('Pit Depth', fontsize = 16)\n",
    "plt.ylabel('PDF', fontsize = 16)\n",
    "\n",
    "plt.hist(Y_3_array[0], bins_no, color = 'black', range=(measurement_bins_start_3, measurement_bins_end_3), histtype='step',\\\n",
    "         density=False, linewidth=2,label='Y_3_array');\n",
    "\n",
    "# plt.hist(Cleaned_Measured_Depth.Y_3_1[1:1443], bins_no, color = 'blue', range=(measurement_bins_start_3, measurement_bins_end_3), histtype='step', normed=False, linewidth=2,\\\n",
    "#          label='Cleaned_Measured_Depth.Y_3_1');\n",
    "# plt.hist(Cleaned_Measured_Depth.Y_3_2[1:269], bins_no, color = 'red', range=(measurement_bins_start_3, measurement_bins_end_3), histtype='step', normed=False, linewidth=2,\\\n",
    "#          label='Cleaned_Measured_Depth.Y_3_2');\n",
    "# plt.hist(Cleaned_Measured_Depth.Y_3_3[1:109], bins_no, color = 'green', range=(measurement_bins_start_3, measurement_bins_end_3), histtype='step', normed=False, linewidth=2,\\\n",
    "#          label='Cleaned_Measured_Depth.Y_3_3');\n",
    "\n",
    "plt.hist(Y_prime_3_1[0], bins_no, color = 'blue', range=(measurement_bins_start_3, measurement_bins_end_3), histtype='step', density=False, linewidth=1,\\\n",
    "         label='Expected_Measured_Depth, Y_prime_3_1');\n",
    "plt.hist(Y_prime_3_2[0], bins_no, color = 'red', range=(measurement_bins_start_3, measurement_bins_end_3), histtype='step', density=False, linewidth=1,\\\n",
    "         label='Expected_Measured_Depth, Y_prime_3_2');\n",
    "plt.hist(Y_prime_3_3[0], bins_no, color = 'green', range=(measurement_bins_start_3, measurement_bins_end_3), histtype='step', density=False, linewidth=1,\\\n",
    "         label='Expected_Measured_Depth, Y_prime_3_3');\n",
    "\n",
    "plt.xlim([measurement_bins_start_3, 20]);\n",
    "plt.title('' , fontsize = measurement_bins_end_3)\n",
    "plt.legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the frequency of each bin for Y_prime_3_1 using the same start and end bin as Y_3\n",
    "(Y_prime_3_1_N, measurement_bins_3, patches) = plt.hist(Y_prime_3_1[0], bins_no,\\\n",
    "                                     range=(measurement_bins_start_3, measurement_bins_end_3),\\\n",
    "                                     histtype='step', density=False, linewidth=2, color = 'blue',\\\n",
    "                                     label='Y_prime_3_1');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the frequency of each bin for Y_prime_3_2 using the same start and end bin as Y_3\n",
    "(Y_prime_3_2_N, measurement_bins_3, patches) = plt.hist(Y_prime_3_2[0], bins_no,\\\n",
    "                                     range=(measurement_bins_start_3, measurement_bins_end_3),\\\n",
    "                                     histtype='step', density=False, linewidth=2, color = 'red',\\\n",
    "                                     label='Y_prime_3_2');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the frequency of each bin for Y_prime_3_3 using the same start and end bin as Y_3\n",
    "(Y_prime_3_3_N, measurement_bins_3, patches) = plt.hist(Y_prime_3_3[0], bins_no,\\\n",
    "                                     range=(measurement_bins_start_3, measurement_bins_end_3),\\\n",
    "                                     histtype='step', density=False, linewidth=2, color = 'green',\\\n",
    "                                     label='Y_prime_3_3');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figureing out which detected pit at t_3 belongs to which population 3_1 or 3_2 or 3_3\n",
    "Y_3_1_bins_freq = pd.DataFrame(0, index = range(0, bins_no), columns = range(1)).astype(int) \n",
    "Y_3_2_bins_freq = pd.DataFrame(0, index = range(0, bins_no), columns = range(1)).astype(int) \n",
    "Y_3_3_bins_freq = pd.DataFrame(0, index = range(0, bins_no), columns = range(1)).astype(int) \n",
    "\n",
    "bin_index_3 = pd.DataFrame(np.zeros(len(Y_3_array))).astype(int)\n",
    "\n",
    "Y_prime_3_1_No = 0\n",
    "Y_prime_3_2_No = 0\n",
    "Y_prime_3_3_No = 0\n",
    "\n",
    "# identifying the bin index for each measured value\n",
    "for i in range(0, len(Y_3_array)):    \n",
    "    for j in range(0, bins_no):\n",
    "        if Y_3.measurement[i] > measurement_bins_3[j] and Y_3.measurement[i] < measurement_bins_3[j+1]:\n",
    "            bin_index_3.iloc[i] = np.int(j)\n",
    "            break     \n",
    "    \n",
    "for i in range(0, len(Y_3_array)):     \n",
    "    if Y_3_1_bins_freq[0][bin_index_3[0][i]] < Y_prime_3_1_N[bin_index_3[0][i]]:            \n",
    "            Y_3.cluster_index[i] = 1\n",
    "            Y_3_1_bins_freq[0][bin_index_3[0][i]] = Y_3_1_bins_freq[0][bin_index_3[0][i]] + 1\n",
    "            Y_prime_3_1_No = Y_prime_3_1_No + 1\n",
    "    elif Y_3_2_bins_freq[0][bin_index_3[0][i]] < Y_prime_3_2_N[bin_index_3[0][i]]:            \n",
    "        Y_3.cluster_index[i] = 2\n",
    "        Y_3_2_bins_freq[0][bin_index_3[0][i]] = Y_3_2_bins_freq[0][bin_index_3[0][i]] + 1\n",
    "        Y_prime_3_2_No = Y_prime_3_2_No + 1 \n",
    "    else:\n",
    "        Y_3.cluster_index[i] = 3\n",
    "        Y_3_3_bins_freq[0][bin_index_3[0][i]] = Y_3_3_bins_freq[0][bin_index_3[0][i]] + 1\n",
    "        Y_prime_3_3_No = Y_prime_3_3_No + 1 \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of PDF of expected measured data at ILI_3\n",
    "tt = np.linspace(-10, 50, 1000)\n",
    "plt.figure(figsize=(12, 9))\n",
    "plt.xlabel('Pit Depth', fontsize = 16)\n",
    "plt.ylabel('PDF', fontsize = 16)\n",
    "plt.plot(tt, norm.pdf(tt, mean_Y_prime_3_1, STD_Y_prime_3_1), c='green', linestyle='--', alpha=0.5,  linewidth=3,\\\n",
    "         label='y_prime_ILI_3_1') \n",
    "plt.plot(tt, norm.pdf(tt, mean_Y_prime_3_2, STD_Y_prime_3_2), c='orange', linestyle='--', alpha=0.5,  linewidth=3,\\\n",
    "          label='y_prime_ILI_3_2')\n",
    "plt.plot(tt, norm.pdf(tt, mean_Y_prime_3_3, STD_Y_prime_3_3), c='blue', linestyle='--', alpha=0.5,  linewidth=3,\\\n",
    "          label='y_prime_ILI_3_3')\n",
    "plt.xlim([-20, 20]);\n",
    "plt.title('' , fontsize = 16)\n",
    "plt.legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of PMF of expected measured data at ILI_3\n",
    "plt.figure(figsize=(12, 9))\n",
    "plt.xlabel('Pit Depth', fontsize = 16)\n",
    "plt.ylabel('PDF', fontsize = 16)\n",
    "# Change these bins start and end to 3\n",
    "plt.hist(Y_prime_3_1[0], bins_no, color = 'blue', range=(measurement_bins_start_3, measurement_bins_end_3), histtype='step', density=False, linewidth=2,\\\n",
    "         label='Expected_Measured_Depth, Y_prime_3_1');\n",
    "plt.hist(Y_prime_3_2[0], bins_no, color = 'red', range=(measurement_bins_start_3, measurement_bins_end_3), histtype='step', density=False, linewidth=1,\\\n",
    "         label='Expected_Measured_Depth, Y_prime_3_2');\n",
    "plt.hist(Y_prime_3_3[0], bins_no, color = 'green', range=(measurement_bins_start_3, measurement_bins_end_3), histtype='step', density=False, linewidth=1,\\\n",
    "         label='Expected_Measured_Depth, Y_prime_3_3');\n",
    "\n",
    "plt.xlim([-2, 20]);\n",
    "plt.title('' , fontsize = 16)\n",
    "plt.legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_3.to_csv('Y_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the arrays of Y_3_1 and Y_3_2 and Y_3_3\n",
    "Y_3_1 = pd.DataFrame(0, index = range(1, Y_prime_3_1_No+1), columns = range(1)).astype(float)\n",
    "Y_3_2 = pd.DataFrame(0, index = range(1, Y_prime_3_2_No+1), columns = range(1)).astype(float)\n",
    "Y_3_3 = pd.DataFrame(0, index = range(1, Y_prime_3_3_No+1), columns = range(1)).astype(float)\n",
    "j1 = 1\n",
    "j2 = 1\n",
    "j3 = 1\n",
    "for i in range (0, len(Y_3_array)): \n",
    "    if Y_3.cluster_index[i] == 1:\n",
    "        Y_3_1.loc[j1][0] = Y_3.measurement[i]  \n",
    "        j1 = j1 + 1\n",
    "    elif Y_3.cluster_index[i] == 2:\n",
    "        Y_3_2.loc[j2][0] = Y_3.measurement[i]  \n",
    "        j2 = j2 + 1\n",
    "    elif Y_3.cluster_index[i] == 3:\n",
    "        Y_3_3.loc[j3][0] = Y_3.measurement[i]  \n",
    "        j3 = j3 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 9))\n",
    "plt.xlabel('Pit Depth', fontsize = 16)\n",
    "plt.ylabel('PDF', fontsize = 16)\n",
    "\n",
    "\n",
    "plt.hist(Y_3.measurement, bins_no, color = 'black', range=(bins_start_2, bins_end_2), histtype='step', density=False, linewidth=2,\\\n",
    "         label='Y_3');\n",
    "plt.hist(Y_3_1[0], bins_no, color = 'blue', range=(bins_start_2, bins_end_2), histtype='step', density=False, linewidth=1,\\\n",
    "         label='Y_3_1');\n",
    "plt.hist(Y_3_2[0], bins_no, color = 'red', range=(bins_start_2, bins_end_2), histtype='step', density=False, linewidth=1,\\\n",
    "         label='Y_3_2');\n",
    "plt.hist(Y_3_3[0], bins_no, color = 'green', range=(bins_start_2, bins_end_2), histtype='step', density=False, linewidth=1,\\\n",
    "         label='Y_3_3');\n",
    "\n",
    "\n",
    "plt.xlim([-2, 20]);\n",
    "plt.title('' , fontsize = 16)\n",
    "plt.legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_3_1.to_csv('Y_3_1.csv')\n",
    "Y_3_2.to_csv('Y_3_2.csv')\n",
    "Y_3_3.to_csv('Y_3_3.csv')\n",
    "Y_3.to_csv('Y_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-2- Use the Clustered ILI_3 measurement data to update the hyper-parameters and estimate the actual depth of the detected pits in OpenBUGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual shape parameter at ILI 3 for pits that are initiated before ILI 1\n",
    "alpha_actual_3_1 = k * (ILI_info.ILI_time[2] - 0) ** nu\n",
    "alpha_actual_3_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual shape parameter at ILI 3 for pits that are initiated between ILI 1 and ILI 2\n",
    "alpha_actual_3_2 = k * (ILI_info.ILI_time[2] - ILI_info.ILI_time[0]) ** nu\n",
    "alpha_actual_3_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual shape parameter at ILI 3 for pits that are initiated between ILI 2 and ILI 3\n",
    "alpha_actual_3_3 = k * (ILI_info.ILI_time[2] - ILI_info.ILI_time[1]) ** nu\n",
    "alpha_actual_3_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimated parameters at ILI 3 by OpenBUGS before considering POD \n",
    "k_3  = 0.1604\n",
    "nu_3 = 0.6631\n",
    "ScalePar_3 = 3.169\n",
    "alpha_3_1_Est = 1.852\n",
    "alpha_3_2_Est = 0.7384\n",
    "alpha_3_3_Est = 0.466"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimated actual depth by OpenBUGS for detected pits at ILI 3\n",
    "#D_3_1 = pd.read_excel('D.xlsx', sheetname='D_3_1')\n",
    "#D_3_2 = pd.read_excel('D.xlsx', sheetname='D_3_2')\n",
    "#D_3_3 = pd.read_excel('D.xlsx', sheetname='D_3_3')\n",
    "D_3   = pd.read_excel('D.xlsx', sheetname='D_3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5-3- Estimate the number of actual pits and their actual depth at  t_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating number of pits at each bin of the PMF of actual depth of truly detected pits at t_3\n",
    "(estimated_N_WO_POD_3, bins_3, patches3) = plt.hist(D_3['depth'], bins_no, \\\n",
    "                                                 histtype='step', density=False, linewidth=2, color = 'red',\\\n",
    "                                                 label='Distribution of estimated depth of detected pits');\n",
    "frequency_info_3.actual_N = actual_N_3\n",
    "frequency_info_3.estimated_N_WO_POD = estimated_N_WO_POD_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the number of actual pits (M_3) given the number of truly detected pits (m_3) at ILI_3:\n",
    "for i in range (1, bins_no+1):\n",
    "    POD = 1-np.exp(-(bins_3[i-1]+bins_3[i])/2/detection_threshold)\n",
    "    frequency_info_3.estimated_N_W_POD[i] = frequency_info_3.estimated_N_WO_POD[i]/POD\n",
    "frequency_info_3.rounded_estimated_N_W_POD = np.round(frequency_info_3.estimated_N_W_POD, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_info_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimated number of existing pits at t_3\n",
    "M_3 = np.int(np.sum(frequency_info_3.rounded_estimated_N_W_POD))\n",
    "M_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed_number)\n",
    "X_3 = pd.DataFrame(0, index = range(0, M_3), columns = range(1)).astype(float) \n",
    "for i in range(0, No_TrueCalled_Pits[2][1]): # change this to m_2\n",
    "    X_3[0][i] = D_3['depth'][i]\n",
    "# estimate the actual depth of undetected pits and find the distribution of X_3\n",
    "\n",
    "jj = 0\n",
    "for i in range(1, bins_no+1):      \n",
    "    if frequency_info_3.rounded_estimated_N_W_POD[i] > frequency_info_3.estimated_N_WO_POD[i]:        \n",
    "        for j in range(1, np.int(frequency_info_3.rounded_estimated_N_W_POD[i] - frequency_info_3.estimated_N_WO_POD[i])+1):          \n",
    "            X = np.random.uniform(bins_3[i-1], bins_3[i])\n",
    "            X_3[0][No_TrueCalled_Pits[2][1] + jj] = X # change this to m_3\n",
    "            jj = jj + 1     \n",
    "X_3.to_csv('X_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual comparison between actual and estimated depth for X_3\n",
    "plt.figure(figsize=(12, 9))\n",
    "plt.xlabel('Pit Depth (mm)', fontsize = 20)\n",
    "plt.ylabel('PMF', fontsize = 20)\n",
    "bins_start_X_3 = np.int(np.min([np.min(pd.concat([Initiation_3_Actual_Depth[0], Initiation_2_Actual_Depth[1],\\\n",
    "                                                Initiation_1_Actual_Depth[2]])), np.min(X_3[0])]))\n",
    "bins_end_X_3   = np.int(np.max([np.max(pd.concat([Initiation_3_Actual_Depth[0], Initiation_2_Actual_Depth[1],\\\n",
    "                                                Initiation_1_Actual_Depth[2]])), np.max(X_3[0])]))\n",
    "plt.hist(pd.concat([Initiation_3_Actual_Depth[0], Initiation_2_Actual_Depth[1], Initiation_1_Actual_Depth[2]]),\\\n",
    "         bins_no, color = 'green', range=(bins_start_X_3, bins_end_X_3), histtype='step', density=True, linewidth=2,\\\n",
    "         label='Simulated actual depth (X_3) at t_3');\n",
    "plt.hist(X_3[0], bins_no, color = 'red', range=(bins_start_X_3, bins_end_X_3), histtype='step', density=True, linewidth=1,\\\n",
    "         label='Estimated actual depth (X_3) at t_3');\n",
    "\n",
    "plt.xlim([bins_start_X_3, 30]);\n",
    "plt.title('' , fontsize = 16)\n",
    "plt.legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(actual_N_3, bins_3, patches) = plt.hist(pd.concat([Initiation_3_Actual_Depth[0], Initiation_2_Actual_Depth[1],\\\n",
    "                                                    Initiation_1_Actual_Depth[2]]), bins_no, \\\n",
    "                                         range=(bins_start_X_3, bins_end_X_3), histtype='step', density=False, linewidth=2,\\\n",
    "                                         color = 'blue', label='Distribution of actual samples ILI_3');\n",
    "(estimated_N_W_POD_3, bins_3, patches3) = plt.hist(X_3[0], bins_no, range=(bins_start_X_3, bins_end_X_3),\\\n",
    "                                                 histtype='step', density=False, linewidth=2, color = 'red',\\\n",
    "                                                 label='Distribution of estimated depth of detected pits');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_Actual_3 = pd.concat([Initiation_3_Actual_Depth[0],\\\n",
    "                Initiation_2_Actual_Depth[1], Initiation_1_Actual_Depth[2]]).shape[0]\n",
    "N_Estimated_3 = X_3.shape[0] \n",
    "KLD3 = KL_divergences(actual_N_3/N_Actual_3, estimated_N_WO_POD_3/N_Estimated_3, bins_no)\n",
    "KLD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SKLD3 = (KL_divergences(actual_N_3/N_Actual_3, estimated_N_WO_POD_3/N_Estimated_3, bins_no) + \\\n",
    "         KL_divergences(estimated_N_WO_POD_3/N_Estimated_3, actual_N_3/N_Actual_3, bins_no))/2\n",
    "SKLD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ChiSq_3 = 0\n",
    "for i in range(0, bins_no):\n",
    "    if actual_N_3[i] > 0 or estimated_N_W_POD_3[i] > 0:\n",
    "        ChiSq_3 = ChiSq_3 + (actual_N_3[i]/N_Actual_3 - estimated_N_W_POD_3[i]/N_Estimated_3)**2/\\\n",
    "        (actual_N_3[i]/N_Actual_3 + estimated_N_W_POD_3[i]/N_Estimated_3)\n",
    "ChiSq_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6- Prediction step at time t_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HPP_rate = (M_1_1+M_2 - M_1_1+M_3 - M_2)/(ILI_info.ILI_time[2])\n",
    "HPP_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_4_4 = np.int((ILI_info.ILI_time[3]-ILI_info.ILI_time[2])*HPP_rate) # this is the mean value of numbers\n",
    "M_4_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_actual_4_1 = k_3 * (ILI_info.ILI_time[3] - 0) ** nu_3\n",
    "alpha_actual_4_2 = k_3 * (ILI_info.ILI_time[3] - ILI_info.ILI_time[0]) ** nu_3\n",
    "alpha_actual_4_3 = k_3 * (ILI_info.ILI_time[3] - ILI_info.ILI_time[1]) ** nu_3\n",
    "alpha_actual_4_4 = k_3 * (ILI_info.ILI_time[3] - ILI_info.ILI_time[2]) ** nu_3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed_number)\n",
    "X_4_1 = pd.DataFrame(0, index = range(1, M_1_1+1), columns = range(1)).astype(float)\n",
    "X_4_1[0] = np.random.gamma(alpha_actual_4_1, scale=ScalePar_3, size=M_1_1) \n",
    "X_4_2 = pd.DataFrame(0, index = range(1, M_2 - M_1_1+1), columns = range(1)).astype(float)\n",
    "X_4_2[0] = np.random.gamma(alpha_actual_4_2, scale=ScalePar_3, size=M_2 - M_1_1)\n",
    "X_4_3 = pd.DataFrame(0, index = range(1, M_3 - M_2+1), columns = range(1)).astype(float)\n",
    "X_4_3[0] = np.random.gamma(alpha_actual_4_3, scale=ScalePar_3, size= M_3 - M_2) \n",
    "X_4_4 = pd.DataFrame(0, index = range(1, M_4_4+1), columns = range(1)).astype(float)\n",
    "X_4_4[0] = np.random.gamma(alpha_actual_4_4, scale=ScalePar_3, size=M_4_4) \n",
    "X_4 = pd.concat([X_4_1, X_4_2, X_4_3, X_4_4], axis=0, ignore_index=False)\n",
    "X_4.to_csv('X_4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed_number)\n",
    "X_4_1 = pd.DataFrame(0, index = range(1, M_1_1+1), columns = range(1)).astype(float)\n",
    "for i in range (1, M_1_1+1):\n",
    "    X_4_1[0][i] = np.random.gamma(k_3 * (ILI_info.ILI_time[3] - np.random.uniform(0, ILI_info.ILI_time[0]))\\\n",
    "                                  ** nu_3, scale=ScalePar_3) \n",
    "\n",
    "X_4_2 = pd.DataFrame(0, index = range(1, M_2 - M_1_1+1), columns = range(1)).astype(float)\n",
    "for i in range (1, M_2 - M_1_1+1):\n",
    "    X_4_2[0][i] = np.random.gamma(k_3 * (ILI_info.ILI_time[3] - np.random.uniform(ILI_info.ILI_time[0],\\\n",
    "                                   ILI_info.ILI_time[1])) ** nu_3, scale=ScalePar_3) \n",
    "\n",
    "X_4_3 = pd.DataFrame(0, index = range(1, M_3 - M_2+1), columns = range(1)).astype(float)\n",
    "for i in range (1, M_3 - M_2+1):\n",
    "    X_4_3[0][i] = np.random.gamma(k_3 * (ILI_info.ILI_time[3] - np.random.uniform(ILI_info.ILI_time[1],\\\n",
    "                                   ILI_info.ILI_time[2])) ** nu_3, scale=ScalePar_3) \n",
    "\n",
    "X_4_4 = pd.DataFrame(0, index = range(1, M_4_4+1), columns = range(1)).astype(float)\n",
    "for i in range (1, M_4_4+1):\n",
    "    X_4_4[0][i] = np.random.gamma(k_3 * (ILI_info.ILI_time[3] - np.random.uniform(ILI_info.ILI_time[2],\\\n",
    "                                   ILI_info.ILI_time[3])) ** nu_3, scale=ScalePar_3) \n",
    "\n",
    "\n",
    "X_4 = pd.concat([X_4_1, X_4_2, X_4_3, X_4_4], axis=0, ignore_index=False)\n",
    "X_4.to_csv('X_4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual comparison between actual and estimated depth for X_4\n",
    "plt.figure(figsize=(12, 9))\n",
    "plt.xlabel('Pit Depth (mm)', fontsize = 20)\n",
    "plt.ylabel('PMF', fontsize = 20)\n",
    "bins_start_X_4 = np.int(np.min([np.min(pd.concat([Prediction_Actual_Depth[0], Initiation_3_Actual_Depth[1],\\\n",
    "                                                Initiation_2_Actual_Depth[2], Initiation_1_Actual_Depth[3]])),\\\n",
    "                              np.min(X_4[0])]))\n",
    "bins_end_X_4   = np.int(np.max([np.max(pd.concat([Prediction_Actual_Depth[0], Initiation_3_Actual_Depth[1],\\\n",
    "                                                Initiation_2_Actual_Depth[2], Initiation_1_Actual_Depth[3]])),\\\n",
    "                              np.max(X_4[0])]))\n",
    "plt.hist(pd.concat([Prediction_Actual_Depth[0], Initiation_3_Actual_Depth[1], Initiation_2_Actual_Depth[2],\\\n",
    "                    Initiation_1_Actual_Depth[3]]), bins_no, color = 'green', range=(bins_start_X_4, bins_end_X_4),\\\n",
    "         histtype='step', density=True, linewidth=2, label='Simulated actual depth (X_4) at t_4');\n",
    "plt.hist(X_4[0], bins_no, color = 'red', range=(bins_start_X_4, bins_end_X_4), histtype='step', density=True,\\\n",
    "         linewidth=1, label='Estimated actual depth (X_4) at t_4');\n",
    "\n",
    "plt.xlim([bins_start_X_4, 30]);\n",
    "plt.title('' , fontsize = 16)\n",
    "plt.legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating number of pits at each bin of the PMF of actual depth and estimated depth without POD\n",
    "(actual_N_4, bins_4, patches) = plt.hist(pd.concat([Prediction_Actual_Depth[0], Initiation_3_Actual_Depth[1],\\\n",
    "                                                    Initiation_2_Actual_Depth[2], Initiation_1_Actual_Depth[3]]),\\\n",
    "                                         bins_no, range=(bins_start_X_4, bins_end_X_4), histtype='step', density=False,\\\n",
    "                                         linewidth=2, color = 'blue', label='Distribution of actual samples ILI_3');\n",
    "(estimated_N_WO_POD_4, bins_4, patches4) = plt.hist(X_4[0], bins_no,range=(bins_start_X_4, bins_end_X_4), \\\n",
    "                                                 histtype='step', density=False, linewidth=2, color = 'red',\\\n",
    "                                                 label='Distribution of estimated depth of detected pits');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_Actual_4 = pd.concat([Prediction_Actual_Depth[0], Initiation_3_Actual_Depth[1],\\\n",
    "                Initiation_2_Actual_Depth[2], Initiation_1_Actual_Depth[3]]).shape[0]\n",
    "N_Estimated_4 = X_4.shape[0] \n",
    "KLD4 = KL_divergences(actual_N_4/N_Actual_4, estimated_N_WO_POD_4/N_Estimated_4, bins_no)\n",
    "KLD4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SKLD4 = (KL_divergences(actual_N_4/N_Actual_4, estimated_N_WO_POD_4/N_Estimated_4, bins_no) + \\\n",
    "         KL_divergences(estimated_N_WO_POD_4/N_Estimated_4, actual_N_4/N_Actual_4, bins_no))/2\n",
    "SKLD4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ChiSq_4 = 0\n",
    "for i in range(0, bins_no):\n",
    "    if actual_N_4[i] > 0 or estimated_N_WO_POD_4[i] > 0:\n",
    "        ChiSq_4 = ChiSq_4 + (actual_N_4[i]/N_Actual_4 - estimated_N_WO_POD_4[i]/N_Estimated_4)**2\\\n",
    "        /(actual_N_4[i]/N_Actual_4 + estimated_N_WO_POD_4[i]/N_Estimated_4)\n",
    "ChiSq_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Results = pd.DataFrame(0, index = range(1, 10), columns = range(4)).astype(float)\n",
    "Results.columns = ['assumed', 'ILI_1', 'ILI_2', 'ILI_3']\n",
    "Results.index = ['k', 'nu', 'ScalePar', 'OB: alpha_1_1', 'OB: alpha_2_1', 'OB: alpha_2_2', 'OB: alpha_3_1',\\\n",
    "                 'OB: alpha_3_2', 'OB: alpha_3_3']\n",
    "Results.assumed[0] = k\n",
    "Results.assumed[1] = nu\n",
    "Results.assumed[2] = ScalePar\n",
    "Results.assumed[3] = alpha_1_1_actual\n",
    "Results.assumed[4] = alpha_2_1_actual\n",
    "Results.assumed[5] = alpha_2_2_actual\n",
    "Results.assumed[6] = alpha_3_1_actual\n",
    "Results.assumed[7] = alpha_3_2_actual\n",
    "Results.assumed[8] = alpha_3_3_actual\n",
    "Results.ILI_1[0] = k_1\n",
    "Results.ILI_1[1] = nu_1\n",
    "Results.ILI_1[2] = ScalePar_1\n",
    "Results.ILI_1[3] = alpha_1_1_Est\n",
    "Results.ILI_2[0] = k_2\n",
    "Results.ILI_2[1] = nu_2\n",
    "Results.ILI_2[2] = ScalePar_2\n",
    "Results.ILI_2[4] = alpha_2_1_Est\n",
    "Results.ILI_2[5] = alpha_2_2_Est \n",
    "Results.ILI_3[0] = k_3\n",
    "Results.ILI_3[1] = nu_3\n",
    "Results.ILI_3[2] = ScalePar_3\n",
    "Results.ILI_3[6] = alpha_3_1_Est\n",
    "Results.ILI_3[7] = alpha_3_2_Est\n",
    "Results.ILI_3[8] = alpha_3_3_Est\n",
    "\n",
    "Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ILI_info.Estimated_Pit_No[0] = M_1_1\n",
    "ILI_info.Estimated_Pit_No[1] = M_2 - M_1_1\n",
    "ILI_info.Estimated_Pit_No[2] = M_3 - M_2\n",
    "ILI_info.Estimated_Pit_No[3] = M_4_4\n",
    "ILI_info.KLD[0] = np.round(KLD1,2)\n",
    "ILI_info.KLD[1] = KLD2\n",
    "ILI_info.KLD[2] = KLD3\n",
    "ILI_info.KLD[3] = KLD4\n",
    "ILI_info.ChiSq[0] = ChiSq_1\n",
    "ILI_info.ChiSq[1] = ChiSq_2\n",
    "ILI_info.ChiSq[2] = ChiSq_3\n",
    "ILI_info.ChiSq[3] = ChiSq_4\n",
    "ILI_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pit_generation_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HPP_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PosNormal(mean, sigma):\n",
    "    x = np.random.normal(mean,sigma)\n",
    "    return(x if x>=0 else PosNormal(mean,sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CumulativeHist (bins_No, Freqs):\n",
    "    CH = np.zeros (bins_No)\n",
    "    for i in range(1, bins_No):\n",
    "        CH[i] = CH[i-1] + Freqs[i-1]\n",
    "    return(CH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DiscMCS(CumulHist, bins, bins_no):\n",
    "    rand = np.random.uniform(0,1)*CumulHist[bins_no-1]\n",
    "    for i in range(1, bins_no):\n",
    "        if rand > CumulHist[i-1] and rand < CumulHist[i]:\n",
    "            sample = ((bins[i]-bins[i-1])*rand-bins[i]*CumulHist[i-1]+bins[i-1]*CumulHist[i])/\\\n",
    "            (CumulHist[i] - CumulHist[i-1])\n",
    "    return(sample)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CumuHist_X_4 = CumulativeHist(bins_no, estimated_N_WO_POD_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed_number)\n",
    "MCSIterNo = 10000\n",
    "Operating_pressure_mean = 6.66       # MPa\n",
    "Operating_pressure_STD  = Operating_pressure_mean * 0.02 # MPa\n",
    "# Calculating probability of small leak at each time\n",
    "prob_of_failure = pd.DataFrame(0, index=range(1, 1), columns=range(4)).astype(float)\n",
    "prob_of_failure.columns = [\"Safe\", \"Small Leak\", \"Large Leak\", \"Rupture\"]\n",
    "OperPressSamples = pd.DataFrame(0, index=range(0, MCSIterNo), columns=range(1)).astype(float)\n",
    "BurstPressSamples = pd.DataFrame(0, index=range(1), columns=range(1)).astype(float)\n",
    "RupturePressSamples = pd.DataFrame(0, index=range(1), columns=range(1)).astype(float)\n",
    "PWTSamples = pd.DataFrame(0, index=range(0, MCSIterNo), columns=range(1)).astype(float)\n",
    "X_4_sample = np.zeros(MCSIterNo)\n",
    "for i in range(0, MCSIterNo):\n",
    "    X_4_sample[i] = DiscMCS(CumuHist_X_4, bins_4, bins_no)\n",
    "\n",
    "## Samplin from a histogram X_4\n",
    "# Cumalative histogram CX_4\n",
    "pit_length_mean = 15 # mm\n",
    "pit_length_STD  = 3 # mm\n",
    "small_leak_threshold = 0.8 * PWT # 0.8 is the common value in the literature\n",
    "ultimate_tensile_strength_mean = 456  # MPa\n",
    "ultimate_tensile_strength_STD = ultimate_tensile_strength_mean * 0.03  # MPa\n",
    "epsilon = 1\n",
    "outer_diameter = 506  # mm\n",
    "\n",
    "N_small   = 0\n",
    "N_large   = 0\n",
    "N_rupture = 0\n",
    "Counter = 0\n",
    "for k in range(0, MCSIterNo):       \n",
    "    pit_length = PosNormal(pit_length_mean, pit_length_STD)\n",
    "    UTS = PosNormal(ultimate_tensile_strength_mean, ultimate_tensile_strength_STD)\n",
    "    Op_pressure = PosNormal(Operating_pressure_mean, Operating_pressure_STD)\n",
    "    PWTSample1 = PosNormal(Operating_pressure_mean, Operating_pressure_STD)\n",
    "    PWTSample = PWT\n",
    "    OperPressSamples.loc[k,0] = Op_pressure    \n",
    "    PWTSamples.loc[k,0] = PWTSample1\n",
    "    f1 = small_leak_threshold - X_4_sample[k]\n",
    "    if f1 <= 0 :#and f2 > 0:\n",
    "        N_small  = N_small + 1\n",
    "    else:\n",
    "        # burst pressure\n",
    "        Pb = epsilon * UTS * PWTSample / outer_diameter * (1 - X_4_sample[k]/ PWTSample *\\\n",
    "            (1- np.exp(-0.157 * pit_length / np.sqrt(outer_diameter*(PWTSample - X_4_sample[k]) / 2))))\n",
    "        if pit_length**2 / (outer_diameter * PWTSample) <= 50:\n",
    "            M = np.sqrt(1+0.6275 * pit_length**2/(outer_diameter * PWTSample)-0.003375*pit_length**4 \\\n",
    "                        / (outer_diameter * PWTSample)**2)\n",
    "        else:\n",
    "            M =  3.3 + 0.032 * pit_length**2/(outer_diameter * PWTSample) \n",
    "        P_rupture = 2 * PWTSample * 0.9 * UTS / (M * outer_diameter)        \n",
    "        BurstPressSamples.loc[Counter,0] = Pb\n",
    "        RupturePressSamples.loc[Counter,0] = P_rupture\n",
    "        Counter = Counter + 1        \n",
    "        f2 = Pb - Op_pressure\n",
    "        f3 = P_rupture - Op_pressure\n",
    "\n",
    "        if f2 <= 0 and f3 > 0:\n",
    "            N_large  = N_large + 1\n",
    "        if f2 <= 0 and f3 <= 0:\n",
    "            N_rupture  = N_rupture + 1 \n",
    "prob_of_failure.loc[1, 'Small Leak'] = N_small / MCSIterNo\n",
    "prob_of_failure.loc[1, 'Large Leak'] = N_large / MCSIterNo\n",
    "prob_of_failure.loc[1, 'Rupture']    = N_rupture / MCSIterNo\n",
    "prob_of_failure.loc[1, 'Safe'] = (MCSIterNo - N_small - N_large - N_rupture) / MCSIterNo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_of_failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some characteristics for plots\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('legend',**{'fontsize':20})\n",
    "plt.rc('xtick', labelsize=20) \n",
    "plt.rc('ytick', labelsize=20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('classic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 9))\n",
    "plt.xlabel('Pressure(MPa)', fontsize = 20)\n",
    "plt.ylabel('PMF', fontsize = 20)\n",
    "# bins_start_X_1 = np.int(np.min([np.min(Initiation_1_Actual_Depth[0]), np.min(X_1[0])]))\n",
    "# bins_end_X_1   = np.int(np.max([np.max(Initiation_1_Actual_Depth[0]), np.max(X_1[0])]))\n",
    "plt.hist(OperPressSamples[0], 100, color = 'green', \\\n",
    "         histtype='step', density=True,  linewidth=2, label='Operating Pressure');\n",
    "plt.hist(BurstPressSamples[0], 100, color = 'red', \\\n",
    "          histtype='step', density=True, linewidth=2, label='Burst Pressure');\n",
    "\n",
    "plt.hist(RupturePressSamples[0], 100, color = 'blue', \\\n",
    "          histtype='step', density=True, linewidth=2, label='Rupture Pressure');\n",
    "\n",
    "plt.title('' , fontsize = 20)\n",
    "plt.legend(loc='upper center',)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
